{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 저장된 모델 활용\n",
    "- 모델 파일 종류\n",
    "    * 가중치 및 절편 저장 파일 => 동일한 구조 모델 인스턴스 생성 후 사용 가능\n",
    "    * 모델 전체 저장 파일 => 바로 로딩 후 사용 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'NLP_Class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchinfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mNLP_Class\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'NLP_Class'"
     ]
    }
   ],
   "source": [
    "# 모듈 로딩\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\KDP-50\\OneDrive\\바탕 화면\\KDT_DYH\\10.Natural_Language_Processing')\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from NLPmodules import funcRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델 파일 관련\n",
    "\n",
    "# 저장 경로\n",
    "SAVE_PATH='../Project/saved_models/'\n",
    "\n",
    "# 모델 구조 및 파라미터 모두 저장 파일명\n",
    "# SAVE_MODEL='model_score(0.7739)_loss(0.4754).pth' # 다 1 모델\n",
    "SAVE_MODEL='hun_model_score(0.8598)_loss(0.3825).pth' # 반대로 모델\n",
    "# SAVE_MODEL='model_score(0.9452)_loss(0.1809).pth' # 다 0 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 모델 로딩 - 모델 전체 파일 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP_Model = torch.load(SAVE_PATH+SAVE_MODEL, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceClassifier(\n",
      "  (embedding): Embedding(2695, 128, padding_idx=0)\n",
      "  (model): LSTM(128, 64, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (classifier): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(NLP_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "SentenceClassifier                       --\n",
       "├─Embedding: 1-1                         344,960\n",
       "├─LSTM: 1-2                              198,656\n",
       "├─Linear: 1-3                            129\n",
       "├─Dropout: 1-4                           --\n",
       "=================================================================\n",
       "Total params: 543,745\n",
       "Trainable params: 543,745\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(NLP_Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 예측 <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- vocab 로딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 vocab 파일 불러오기\n",
    "with open('hun_vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MAX_LENGTH=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: False\n"
     ]
    }
   ],
   "source": [
    "# 예시 (결과: 0)\n",
    "data = \"근육 괴사와 독소로 인한 전신증상을 가져오는 중증 질환이다\"\n",
    "prediction = funcRNN.predict_model(NLP_Model, data, vocab, MAX_LENGTH)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: True\n"
     ]
    }
   ],
   "source": [
    "# 예시 (결과: 1)\n",
    "data = \"오늘날의 기준적 수술식은 적응과 요약에도 달려 있지만 일반적으로 경복막 제왕절술이다\"\n",
    "prediction = funcRNN.predict_model(NLP_Model, data, vocab, MAX_LENGTH)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.]])\n"
     ]
    }
   ],
   "source": [
    "# 데이터가 문자열이라면 토큰화 및 인덱스로 변환\n",
    "tokens = [vocab.get(token, vocab['oov']) for token in data]  # 토큰을 인덱스로 변환\n",
    "\n",
    "# 패딩하여 모델의 입력 형태와 일치시키기\n",
    "if len(tokens) < MAX_LENGTH:\n",
    "    tokens = tokens + [vocab['pad']] * (MAX_LENGTH - len(tokens))\n",
    "else:\n",
    "    tokens = tokens[:MAX_LENGTH]\n",
    "\n",
    "dataTS = torch.LongTensor(tokens).unsqueeze(0)\n",
    "\n",
    "# 검증 모드로 모델 설정\n",
    "NLP_Model.eval()\n",
    "with torch.no_grad():\n",
    "    # 추론/평가\n",
    "    logits = NLP_Model(dataTS)\n",
    "    pre_val = torch.sigmoid(logits)\n",
    "\n",
    "prediction = (pre_val >= 0.5).float()\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_TORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
