{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 붓꽃 품종 분류\n",
    "- 목표 : 붓꽃의 3개 품종을 분류하기\n",
    "- 데이터셋 : 내장 데이터셋 사용\n",
    "- 피쳐 : 4개\n",
    "- 타겟 : 품종 1개\n",
    "- 학습 : 지도학습 > 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "[1] 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈로딩\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내장 데이터셋 로딩\n",
    "data=load_iris(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bunch 인스턴스 => dict와 유사한 형태\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureDF=data['data']\n",
    "targetSR=data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureDF.shape, targetSR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       " 0                5.1               3.5                1.4               0.2,\n",
       " 0    0\n",
       " Name: target, dtype: int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureDF.head(1), targetSR.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 학습을 위한 데이터셋 준비 => 학습용, 검증용, 테스트용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 & 테스트용 분리\n",
    "x_train, x_test, y_train, y_test = train_test_split(featureDF, targetSR,\n",
    "                                                    stratify=targetSR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 & 검증용 분리\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,\n",
    "                                                    stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DS: 84 0.56%\n",
      "val DS: 28 0.19%\n",
      "Test DS: 38 0.25%\n"
     ]
    }
   ],
   "source": [
    "print(f'Train DS: {x_train.shape[0]} {x_train.shape[0]/featureDF.shape[0]:.2f}%')\n",
    "print(f'val DS: {x_val.shape[0]} {x_val.shape[0]/featureDF.shape[0]:.2f}%')\n",
    "print(f'Test DS: {x_test.shape[0]} {x_test.shape[0]/featureDF.shape[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 교차검증 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스 생성\n",
    "dtc_model = DecisionTreeClassifier()\n",
    "\n",
    "# [3-1] KFold 기반 --------------------------------------------------\n",
    "# 정확도 저장 리스트\n",
    "accuracys = []\n",
    "\n",
    "# KFold 인스턴스 생성\n",
    "kfold = KFold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_index: [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n",
      "[1번째] 정확도 : 1.0 val 정확도: 1.0\n",
      "train_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n",
      "[2번째] 정확도 : 1.0 val 정확도: 0.9666666666666667\n",
      "train_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n",
      "[3번째] 정확도 : 1.0 val 정확도: 0.8333333333333334\n",
      "train_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n",
      "[4번째] 정확도 : 1.0 val 정확도: 0.9333333333333333\n",
      "train_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119]\n",
      "[5번째] 정확도 : 1.0 val 정확도: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "# k번 만큼 k개 데이터셋으로 학습 진행\n",
    "# -> k등분 후 학습용 데이터셋 인덱스, 검증용 데이터셋 인덱스\n",
    "for idx, (train_index, val_index) in enumerate(kfold.split(featureDF), 1):\n",
    "    \n",
    "    print(f'train_index: {train_index.tolist()}')\n",
    "\n",
    "    # x_train, x_val 데이터셋 설정\n",
    "    x_train, y_train = featureDF.iloc[train_index.tolist()], targetSR[train_index.tolist()]\n",
    "    x_val, y_val = featureDF.iloc[val_index.tolist()], targetSR[val_index.tolist()]\n",
    "\n",
    "    # 학습 진행\n",
    "    dtc_model.fit(x_train, y_train)\n",
    "\n",
    "    # 평가 -> 분류일 경우 score() 메서드는 정확도를 반환해준다.\n",
    "    accuracy=dtc_model.score(x_train, y_train)\n",
    "    val_acc=dtc_model.score(x_val, y_val)\n",
    "    \n",
    "    # accuracys.append(accuracy)\n",
    "    accuracys.append([accuracy, val_acc])\n",
    "    print(f'[{idx}번째] train 정확도 : {accuracy} Val 정확도: {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 정확도:1.0 Val 정확도:0.89\n"
     ]
    }
   ],
   "source": [
    "# 평균 계산\n",
    "train_mean=sum([value[0] for value in accuracys])/kfold.n_splits\n",
    "test_mean=sum([value[1] for value in accuracys])/kfold.n_splits\n",
    "\n",
    "print(f'Train 정확도:{train_mean}, Val 정확도:{test_mean:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_index: [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n",
      "[1번째] 정확도 : 1.0 val 정확도: 0.9666666666666667\n",
      "train_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n",
      "[2번째] 정확도 : 1.0 val 정확도: 0.9666666666666667\n",
      "train_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n",
      "[3번째] 정확도 : 1.0 val 정확도: 0.9\n",
      "train_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n",
      "[4번째] 정확도 : 1.0 val 정확도: 1.0\n",
      "train_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139]\n",
      "[5번째] 정확도 : 1.0 val 정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "### ==> [3-2] StratifiedKfold : 정답/레이블/타겟의 비율을 고려해서 데이터를 나누어줌\n",
    "\n",
    "skfold = StratifiedKFold()\n",
    "\n",
    "# k번 만큼 k개 데이터셋으로 학습 진행\n",
    "# -> k등분 후 학습용 데이터셋 인덱스, 검증용 데이터셋 인덱스\n",
    "for idx, (train_index, val_index) in enumerate(skfold.split(featureDF, targetSR), 1):\n",
    "    \n",
    "    print(f'train_index: {train_index.tolist()}')\n",
    "\n",
    "    # x_train, x_val 데이터셋 설정\n",
    "    x_train, y_train = featureDF.iloc[train_index.tolist()], targetSR[train_index.tolist()]\n",
    "    x_val, y_val = featureDF.iloc[val_index.tolist()], targetSR[val_index.tolist()]\n",
    "\n",
    "    # 학습 진행\n",
    "    dtc_model.fit(x_train, y_train)\n",
    "\n",
    "    # 평가 -> 분류일 경우 score() 메서드는 정확도를 반환해준다.\n",
    "    accuracy=dtc_model.score(x_train, y_train)\n",
    "    val_acc=dtc_model.score(x_val, y_val)\n",
    "    \n",
    "    # accuracys.append(accuracy)\n",
    "    accuracys.append([accuracy, val_acc])\n",
    "    print(f'[{idx}번째] Train 정확도: {accuracy}, Val 정확도: {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 정확도:2.0 Val 정확도:1.86\n"
     ]
    }
   ],
   "source": [
    "# 평균 계산\n",
    "train_mean=sum([value[0] for value in accuracys])/skfold.n_splits\n",
    "test_mean=sum([value[1] for value in accuracys])/skfold.n_splits\n",
    "\n",
    "print(f'Train 정확도:{train_mean} Val 정확도:{test_mean:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 교차검증 및 성능평가 동시 진행 함수\n",
    "    * => cross_val_score, cross_val_predict\n",
    "    * => cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [1] 전체 DS ==> 학습용과 테스트용 DS 분리\n",
    "x_train, x_test, y_train, y_test = train_test_split(featureDF,\n",
    "                                                    targetSR,\n",
    "                                                    stratify=targetSR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cross_val_predict\n",
    "predict = cross_val_predict(dtc_model, featureDF, targetSR, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(f'predict: {predict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cross_val_score\n",
    "predict = cross_val_score(dtc_model, featureDF, targetSR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: [0.96666667 0.96666667 0.9        1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(f'predict: {predict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cross_validate\n",
    "result = cross_validate(dtc_model, x_train, y_train, \n",
    "                        return_train_score=True,\n",
    "                        return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cross_validate\n",
    "result = cross_validate(dtc_model, featureDF, targetSR, \n",
    "                        return_train_score=True,\n",
    "                        return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00226307, 0.00199842, 0.00100017, 0.        , 0.00796413]),\n",
       " 'score_time': array([0.00308275, 0.00099969, 0.00105619, 0.        , 0.00112462]),\n",
       " 'estimator': [DecisionTreeClassifier(),\n",
       "  DecisionTreeClassifier(),\n",
       "  DecisionTreeClassifier(),\n",
       "  DecisionTreeClassifier(),\n",
       "  DecisionTreeClassifier()],\n",
       " 'test_score': array([0.95652174, 0.91304348, 1.        , 1.        , 0.95454545]),\n",
       " 'train_score': array([1., 1., 1., 1., 1.])}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: {'fit_time': array([0.00226307, 0.00199842, 0.00100017, 0.        , 0.00796413]), 'score_time': array([0.00308275, 0.00099969, 0.00105619, 0.        , 0.00112462]), 'estimator': [DecisionTreeClassifier(), DecisionTreeClassifier(), DecisionTreeClassifier(), DecisionTreeClassifier(), DecisionTreeClassifier()], 'test_score': array([0.95652174, 0.91304348, 1.        , 1.        , 0.95454545]), 'train_score': array([1., 1., 1., 1., 1.])}\n"
     ]
    }
   ],
   "source": [
    "print(f'predict: {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_score  train_score\n",
       "0    0.956522          1.0\n",
       "1    0.913043          1.0\n",
       "2    1.000000          1.0\n",
       "3    1.000000          1.0\n",
       "4    0.954545          1.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDF=pd.DataFrame(result).loc[:, ['test_score', 'train_score']]\n",
    "resultDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=result['estimator'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 2, 0, 2, 1, 1, 1, 0, 1, 0, 1, 0, 1, 2, 1, 2, 2, 0,\n",
       "       1, 2, 0, 2, 2, 0, 0, 2, 2, 2, 0, 1, 2, 2, 1, 2])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9210526315789473"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
