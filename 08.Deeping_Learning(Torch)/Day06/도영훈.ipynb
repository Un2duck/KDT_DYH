{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL TEST 2024. 09. 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 퍼셉트론 (Perceptron) 개념에 대해 설명하세요.\n",
    "\n",
    "신경망을 구현할 때 입력층, 은닉층, 출력층으로 구성하며\n",
    "각각의 층에는 가중치(w)와 절편(b)을 받는 퍼셉트론이 형성됨\n",
    "퍼셉트론의 끝에는 활성화함수가 위치함.\n",
    "해당 퍼셉트론에서 다음 퍼셉트론으로 넘어갈 때마다 활성화 함수를 통해 값이 증폭될지 상쇄될지 결정됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 퍼셉트론 (Perceptron) 기본 동작 원리 및 수식을 도식화와 함께 작성해주세요.\n",
    "    - 조건 : 피쳐 4개, 퍼셉트론 1개\n",
    "\n",
    "y = w1x1 + w2x2 + w3x3 + w4x4 + b\n",
    "\n",
    "생성 파라미터는 5개 (가중치 4개, 절편 1개)\n",
    "각 피쳐로부터 값을 받은 뒤(x1,x2,x3,x4)\n",
    "각 가중치를 곱하여 (w1,w2,w3,w4) 절편과 함께 더하여줌."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 활성화함수 (Activation Function)의 역할을 설명하세요.\n",
    "\n",
    "각 층(입력층, 은닉층)의 값을 그 다음층으로 넘길 때 해당 값을 증폭시킬지 상쇄시킬지 결정하여주는 함수임.\n",
    "순전파 과정(입력층>은닉층>출력층)을 통해 값을 계산하며,\n",
    "역전파 과정(출력층>은닉층>입력층)을 통해 역산할때 사용하기도 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 대표적인 활성화함수 (Activation Function)에 대해 설명하세요.\n",
    "\n",
    "    - 최소 4개 이상, 값의 범위\n",
    "- ReLU 함수 >= 0, -> 0보다 작은 값(음수값)은 0으로 만들어주고, 0보다 큰 값(양수값)은 해당 값을 되돌려줌.\n",
    "- Sigmoid 함수 -> 0.0 ~ 1.0 사이 값을 되돌려줌.\n",
    "- Softmax 함수 \n",
    "- step 함수 0 또는 1 -> 0 또는 1의 값을 되돌려줌."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 경사하강법의 개념 및 대표적인 경사하강법 알고리즘에 대해 간략히 설명하세요.\n",
    "    - 최소 3개\n",
    "\n",
    "경사하강법 : 기울기가 최소가 되는 점을 찾아가며 최적의 파라미터를 찾아냄.\n",
    "\n",
    "- Adam\n",
    "- Adamgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 회귀 모델 구현을 간략하게 코드 작성하세요.\n",
    "# - 피쳐 3개\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 모델 이름 : MyRegModel\n",
    "# 부모클래스 : nn.Module\n",
    "# 매개 변수 :\n",
    "# 클래스 설명 : 회귀 모델 구현, 피쳐 3개\n",
    "# ---------------------------------------------------------------------\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class MyRegModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super.__init__()\n",
    "        self.in_layer = nn.Linear(3, 10)\n",
    "        self.hidden_layer = nn.Linear(10, 5)\n",
    "        self.out_layer = nn.Linear(5, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 입력층\n",
    "        y = self.in_layer(x)\n",
    "        y = F.relu(y)\n",
    "\n",
    "        # 은닉층\n",
    "        y = F.relu(self.hidden_layer(y))\n",
    "\n",
    "        # 출력층\n",
    "        return self.out_layer(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 이진분류 모델 구현을 간략하게 코드 작성하세요.\n",
    "# - 피쳐 5개 - 클래스 8개 - 층 : 3 ~ 5개 - 퍼셉트론 : 동적\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 모델 이름 : MyBCFModel\n",
    "# 부모클래스 : nn.Module\n",
    "# 매개 변수 : \n",
    "# 클래스 설명 : 이진분류 모델 구현, 피쳐 5개, 퍼셉트론 : 동적\n",
    "# ---------------------------------------------------------------------\n",
    "class MyBCFModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_out, *hidden):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_layer=nn.Linear(5, hidden[0] if len(hidden) else in_out)\n",
    "        \n",
    "        self.h_layers=nn.ModuleList()\n",
    "        for idx in range(len(hidden)-1):\n",
    "            self.h_layers.append( nn.Linear(hidden[idx], hidden[idx+1]) )\n",
    "\n",
    "        self.out_layer=nn.Linear(hidden[-1] if len(hidden) else in_out, 1)\n",
    "\n",
    "    # 학습 진행 콜백 메서드\n",
    "    def forward(self,x):\n",
    "        # 입력층\n",
    "        y=F.relu(self.in_layer(x))\n",
    "        \n",
    "        # 은닉층\n",
    "        for h_layer in self.h_layers:\n",
    "            y=F.relu(h_layer(y))\n",
    "\n",
    "        # 출력층\n",
    "        return F.sigmoid(self.out_layer(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 다중분류 모델 구현을 간략하게 코드 작성하세요.\n",
    "# - 피쳐 5개 - 클래스 8개 - 층 : 3 ~ 5 퍼셉트론 : 동적 \n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 모델 이름 : MyMCFModel\n",
    "# 부모클래스 : nn.Module\n",
    "# 매개 변수 : \n",
    "# 클래스 설명 : 다중분류 모델 모델 구현, 피쳐 5개\n",
    "# ---------------------------------------------------------------------\n",
    "class MyMCFModel(nn.Module):\n",
    "    def __init__(self, in_in, in_out, out_out, *hidden):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_layer=nn.Linear(in_in, hidden[0] if len(hidden) else in_out)\n",
    "        \n",
    "        self.h_layers=nn.ModuleList()\n",
    "        for idx in range(len(hidden)-1):\n",
    "            self.h_layers.append( nn.Linear(hidden[idx], hidden[idx+1]) )\n",
    "\n",
    "        self.out_layer=nn.Linear(hidden[-1] if len(hidden) else in_out, out_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 입력층\n",
    "        y = F.relu(self.in_layer(x))\n",
    "\n",
    "        # 은닉층\n",
    "        for h_layer in self.h_layers:\n",
    "            y = F.relu(h_layer(y))\n",
    "\n",
    "        # 출력층\n",
    "        y = F.relu(self.out_layer(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 기울기 소실 개념 및 해결 방법을 설명하세요.\n",
    "\n",
    "활성화 함수를 사용하여 DL를 진행할 시 시간이 지날수록 값이 0에 수렴하게 되는 현상.\n",
    "대표적으로 ReLU 함수의 경우 LeakyReLU함수를 사용하여 기울기 소실을 해결할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. 파이토치의 모델 동작 모드에 대해 관련 함수도 함께 설명하세요.\n",
    "\n",
    "- model -> 파이토치의 사용자 정의 모델\n",
    "model.train() => 동작 모드를 training 모드로 전환하여 훈련용 데이터셋 학습을 진행함.\n",
    "\n",
    "model.eval() => 동작 모드를 validate 모드로 전환하여 검증용 데이터셋 학습을 진행함.\n",
    "with.torch.no_grad() => no_grad() 옵션을 통해 훈련에 사용되는 옵션들을 해제."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
