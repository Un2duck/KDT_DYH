{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DNN 기반 회귀 모델 구현 + 학습 진행 모니터링\n",
    "- 데이터셋   : iris.csv\n",
    "- 피쳐/속성  : 3개 Sepal_Length, Sepal_width, Petal_Width\n",
    "- 타겟/라벨  : 1개 Petal_\n",
    "- 학습/방법  : 지도학습 -> 회귀\n",
    "- 알고리즘   : 인공신경망(ANN) -> MLP, DNN : 은닉층이 많은 구성\n",
    "- 프레임워크 : Pytorch\n",
    "\n",
    "***\n",
    "\n",
    "- 모니터링\n",
    "    * 기준 : 검증데이터셋의 loss 또는 score\n",
    "    * 평가 : 학습데이터셋의 loss 또는 score와 비교해서 학습 중단여부 결정\n",
    "    * 선택 : 현재까지 진행된 모델의 파라미터(가중치, 절편) 저장 여부 또는 모델 전체 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 관련 모듈 로딩\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.nn.functional as F  \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchmetrics.regression import R2Score, MeanSquaredError\n",
    "from torchinfo import summary\n",
    "\n",
    "# 데이터 관련 모듈 로딩\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch V.:2.4.1\n",
      "pandas V.:2.0.3\n"
     ]
    }
   ],
   "source": [
    "# 활용 패키지 버전 체크\n",
    "print(f'torch V.:{torch.__version__}')\n",
    "print(f'pandas V.:{pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 데이터 로딩\n",
    "DATA_FILE='../Data/iris.csv'\n",
    "\n",
    "### CSV => DataFrame\n",
    "irisDF = pd.read_csv(DATA_FILE, usecols=[0,1,2,3])\n",
    "\n",
    "### 확인\n",
    "irisDF.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 모델 클래스 설계 및 정의 <hr>\n",
    "- 클래스목적 : iris 데이터를 학습 및 추론\n",
    "- 클래스이름 : irisRegModel\n",
    "- 부모클래스 : nn.Module\n",
    "- 매개 변수 : 층별 입출력 개수 고정하기 때문에 필요 x!\n",
    "- 속성 필드 : \n",
    "- 기능 역할 : __ init__() : 모델 구조 설정, forward() : 순방향 학습 <= 오버라이딩(overriding) - [상속 시 가능!]\n",
    "- 클래스구조\n",
    "    * 입력층 : 입력 3개(피쳐)  출력 10개 (퍼셉트론/뉴런 10개 존재)\n",
    "    * 은닉층 : 입력 10개       출력 30개 (퍼셉트론/뉴런 30개 존재)\n",
    "    * 출력층 : 입력 30개       출력 1개 (너비값)\n",
    "\n",
    "- 활성화함수\n",
    "    * 클래스 형태 ==> ex) nn.MESLoss, nn.ReLU ==> __ init__(self) 메서드\n",
    "    * 함수 형태 ==> torch.nn.functional 아래에 ==> forward(self) 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class irisRegModel(nn.Module):\n",
    "\n",
    "    # 모델 구조 구성 및 인스턴스 생성 메서드\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_layer=nn.Linear(3, 10)\n",
    "        self.hidden_layer=nn.Linear(10, 30)\n",
    "        self.out_layer=nn.Linear(30, 1)\n",
    "\n",
    "    # 순방향 학습 진행 메서드\n",
    "    def forward(self, x):\n",
    "        # - 입력층\n",
    "        y = self.in_layer(x)     # y = f1w1 + f2w2 + f3w3 + b ... -> 10개\n",
    "        y = F.relu(y)            # relu -> y 값의 범위 0 <= y\n",
    "        \n",
    "        # - 은닉층 : 10개의 숫자 값(>=0)\n",
    "        y = self.hidden_layer(y) # y = f21w21 + ... + f210w210 , ... -> 30개\n",
    "        y = F.relu(y)            # relu -> y 값의 범위 0 <= y\n",
    "\n",
    "        # - 출력층 : 1개의 숫자 값(>=0)\n",
    "        return self.out_layer(y)        # f31w31 + ... f330w330 + b -> 1개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irisRegModel(\n",
      "  (in_layer): Linear(in_features=3, out_features=10, bias=True)\n",
      "  (hidden_layer): Linear(in_features=10, out_features=30, bias=True)\n",
      "  (out_layer): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## 모델 인스턴스 생성\n",
    "model = irisRegModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "irisRegModel                             [1000, 1]                 --\n",
       "├─Linear: 1-1                            [1000, 10]                40\n",
       "├─Linear: 1-2                            [1000, 30]                330\n",
       "├─Linear: 1-3                            [1000, 1]                 31\n",
       "==========================================================================================\n",
       "Total params: 401\n",
       "Trainable params: 401\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.40\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.33\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.34\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 사용 메모리 정보 확인\n",
    "summary(model, input_size=(1000,3)) # input_size = ,feature 개수)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 데이터셋 클래스 설계 및 정의 <hr>\n",
    "- 데이터셋 : iris.csv\n",
    "- 피쳐_개수 : 3개\n",
    "- 타겟_개수 : 1개\n",
    "- 클래스이름 : IrisDataset\n",
    "- 부모클래스 : utils.data.Dataset\n",
    "- 속성_필드 : featureDF, targetDF, n_rows, n_features\n",
    "- 필수메서드 : \n",
    "    * __ init__(self): 데이터셋 저장 및 전처리, 개발자가 필요한 속성 설정\n",
    "    * __ len__(self): 데이터의 개수 반환\n",
    "    * __ getitem__(self, index): 특정 인덱스의 피쳐와 타겟 반환\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(Dataset):\n",
    "\n",
    "    def __init__(self, featureDF, targetDF):\n",
    "        self.featureDF=featureDF\n",
    "        self.targetDF=targetDF\n",
    "        self.n_rows=featureDF.shape[0]\n",
    "        self.n_features=featureDF.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 텐서화\n",
    "        featureTS=torch.FloatTensor(self.featureDF.iloc[index].values)\n",
    "        targetTS=torch.FloatTensor(self.targetDF.iloc[index].values)\n",
    "        \n",
    "        # 피쳐와 타겟 반환\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터셋 인스턴스 생성\n",
    "\n",
    "# DataFrame에서 피쳐와 타겟 추출\n",
    "featureDF = irisDF[irisDF.columns[:-1]]     # 2D (150, 3)\n",
    "targetDF = irisDF[irisDF.columns[-1:]]      # 2D (150, 1)\n",
    "\n",
    "# - 커스텀데이터셋 인스턴스 생성\n",
    "irisDS=IrisDataset(featureDF, targetDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 학습 준비\n",
    "- 학습 횟수 : EPOCH          <- 처음~ 끝까지 공부하는 단위\n",
    "- 배치 크기 : BATCH_SIZE     <- 한번에 학습할 데이터셋 양\n",
    "- 위치 지정 : DEVICE         <- 탠서 저장 및 실행 위치 (GPU/CPU)\n",
    "- 학 습 률 : LR 가중치와 절편 업데이트 시 경사하강법으로 업데이트 간격 설정 0.001 ~ 0.1 (낮을수록 촘촘히)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_CNT: 15\n"
     ]
    }
   ],
   "source": [
    "### 학습 진행 관련 설정\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 10\n",
    "BATCH_CNT = irisDF.shape[0]//BATCH_SIZE\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR = 0.001\n",
    "\n",
    "print(f'BATCH_CNT: {BATCH_CNT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인스턴스/객체 : 모델, 데이터셋, 최적화, (손실함수), (성능지표)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X_train(shape): (84, 3) (type): <class 'pandas.core.frame.DataFrame'>], X_test: (38, 3), X_val: (28, 3)\n",
      "[y_train(shape): (84, 1) (type): <class 'pandas.core.frame.DataFrame'>], y_test: (38, 1), y_val: (28, 1)\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스 생성\n",
    "model=irisRegModel()\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "X_train, X_test, y_train, y_test = train_test_split(featureDF, targetDF, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=1)\n",
    "print(f'[X_train(shape): {X_train.shape} (type): {type(X_train)}], X_test: {X_test.shape}, X_val: {X_val.shape}')\n",
    "print(f'[y_train(shape): {y_train.shape} (type): {type(y_train)}], y_test: {y_test.shape}, y_val: {y_val.shape}')\n",
    "\n",
    "trainDS=IrisDataset(X_train, y_train)\n",
    "valDS=IrisDataset(X_val, y_val)\n",
    "testDS=IrisDataset(X_test, y_test)\n",
    "\n",
    "# 데이터로더 인스턴스 생성\n",
    "trainDL=DataLoader(trainDS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3]) torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "## [테스트] 데이터로더\n",
    "for feature, target in trainDL:\n",
    "    # print(feature, target)\n",
    "    print(feature.shape, target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 인스턴스 => W,b 텐서 즉, model.parameters() 전달\n",
    "optimizer=optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# 손실함수 인스턴스 => 회귀 : MSE, MAE, RMSE, ...\n",
    "reg_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 모드 함수\n",
    "def training():\n",
    "    # 학습 모드로 모델 설정\n",
    "    model.train()\n",
    "    # 배치 크기 만큼 데이터 로딩해서 학습 진행\n",
    "    loss_total, score_total=0,0\n",
    "    for featureTS, targetTS in trainDL:\n",
    "\n",
    "        # 학습 진행\n",
    "        pre_y=model(featureTS)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss=reg_loss(pre_y, targetTS)\n",
    "        loss_total+=loss.item()\n",
    "        \n",
    "        # 성능평가 계산\n",
    "        score=R2Score()(pre_y, targetTS)\n",
    "        score_total+=score.item()\n",
    "\n",
    "        # 최적화 진행\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss_total, score_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 모드 함수\n",
    "def validate():\n",
    "    # 검증 모드로 모델 설정\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 검증 데이터셋\n",
    "        val_featureTS=torch.FloatTensor(valDS.featureDF.values)\n",
    "        val_targetTS=torch.FloatTensor(valDS.targetDF.values)\n",
    "        \n",
    "        # 평가\n",
    "        pre_val=model(val_featureTS)\n",
    "\n",
    "        # 손실\n",
    "        loss_val=reg_loss(pre_val, val_targetTS)\n",
    "\n",
    "        # 성능평가\n",
    "        score_val=R2Score()(pre_val, val_targetTS)\n",
    "    return loss_val, score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100 => [TRAIN] LOSS: 22.699562072753906 SCORE: -39.613712310791016\n",
      "\t=> [VAL] LOSS: 2.008556604385376 SCORE: -2.111578941345215\n",
      "2/100 => [TRAIN] LOSS: 9.651025891304016 SCORE: -16.19494390487671\n",
      "\t=> [VAL] LOSS: 1.694421648979187 SCORE: -1.6249330043792725\n",
      "3/100 => [TRAIN] LOSS: 5.3264808257420855 SCORE: -8.431118647257486\n",
      "\t=> [VAL] LOSS: 1.4036709070205688 SCORE: -1.1745131015777588\n",
      "4/100 => [TRAIN] LOSS: 3.1983697563409805 SCORE: -4.608752429485321\n",
      "\t=> [VAL] LOSS: 1.1491702795028687 SCORE: -0.7802506685256958\n",
      "5/100 => [TRAIN] LOSS: 2.005863916873932 SCORE: -2.4807134866714478\n",
      "\t=> [VAL] LOSS: 0.9638012051582336 SCORE: -0.4930838346481323\n",
      "6/100 => [TRAIN] LOSS: 1.321322739124298 SCORE: -1.2876572012901306\n",
      "\t=> [VAL] LOSS: 0.8563657999038696 SCORE: -0.32664918899536133\n",
      "7/100 => [TRAIN] LOSS: 0.941074516092028 SCORE: -0.6640459469386509\n",
      "\t=> [VAL] LOSS: 0.8170455098152161 SCORE: -0.2657356262207031\n",
      "8/100 => [TRAIN] LOSS: 0.7333230152726173 SCORE: -0.36562711000442505\n",
      "\t=> [VAL] LOSS: 0.8048886656761169 SCORE: -0.2469027042388916\n",
      "9/100 => [TRAIN] LOSS: 0.6059568060768975 SCORE: -0.21725509564081827\n",
      "\t=> [VAL] LOSS: 0.7779082655906677 SCORE: -0.20510566234588623\n",
      "10/100 => [TRAIN] LOSS: 0.5120701283216477 SCORE: -0.12431772351264954\n",
      "\t=> [VAL] LOSS: 0.7377106547355652 SCORE: -0.14283311367034912\n",
      "11/100 => [TRAIN] LOSS: 0.43927015228704974 SCORE: -0.06068316372958096\n",
      "\t=> [VAL] LOSS: 0.6896418929100037 SCORE: -0.06836676597595215\n",
      "12/100 => [TRAIN] LOSS: 0.37924618770678836 SCORE: -0.01111909250418345\n",
      "\t=> [VAL] LOSS: 0.6400830149650574 SCORE: 0.008407831192016602\n",
      "13/100 => [TRAIN] LOSS: 0.32907306460233837 SCORE: 0.02989868475840642\n",
      "\t=> [VAL] LOSS: 0.595491886138916 SCORE: 0.07748675346374512\n",
      "14/100 => [TRAIN] LOSS: 0.2859452600990023 SCORE: 0.06644462687628609\n",
      "\t=> [VAL] LOSS: 0.5546625852584839 SCORE: 0.14073801040649414\n",
      "15/100 => [TRAIN] LOSS: 0.2482512652873993 SCORE: 0.09948285818099975\n",
      "\t=> [VAL] LOSS: 0.5148393511772156 SCORE: 0.20243054628372192\n",
      "16/100 => [TRAIN] LOSS: 0.21510197594761848 SCORE: 0.1288156658411026\n",
      "\t=> [VAL] LOSS: 0.47392240166664124 SCORE: 0.2658175826072693\n",
      "17/100 => [TRAIN] LOSS: 0.18591808045611663 SCORE: 0.15432790447683895\n",
      "\t=> [VAL] LOSS: 0.431792676448822 SCORE: 0.33108335733413696\n",
      "18/100 => [TRAIN] LOSS: 0.16016064584255219 SCORE: 0.17642652326160008\n",
      "\t=> [VAL] LOSS: 0.3898780941963196 SCORE: 0.3960157632827759\n",
      "19/100 => [TRAIN] LOSS: 0.13740446536164536 SCORE: 0.1956118439373217\n",
      "\t=> [VAL] LOSS: 0.34913402795791626 SCORE: 0.45913493633270264\n",
      "20/100 => [TRAIN] LOSS: 0.11733630895614625 SCORE: 0.21208073794841767\n",
      "\t=> [VAL] LOSS: 0.3103252947330475 SCORE: 0.5192559957504272\n",
      "21/100 => [TRAIN] LOSS: 0.0996529431570144 SCORE: 0.22615464528401694\n",
      "\t=> [VAL] LOSS: 0.2735944390296936 SCORE: 0.5761579871177673\n",
      "22/100 => [TRAIN] LOSS: 0.08418213779276068 SCORE: 0.23779352415691724\n",
      "\t=> [VAL] LOSS: 0.23940490186214447 SCORE: 0.6291230916976929\n",
      "23/100 => [TRAIN] LOSS: 0.0707254383874976 SCORE: 0.24713984779689624\n",
      "\t=> [VAL] LOSS: 0.2076273262500763 SCORE: 0.6783517003059387\n",
      "24/100 => [TRAIN] LOSS: 0.05912743074198564 SCORE: 0.25421049694220227\n",
      "\t=> [VAL] LOSS: 0.17836956679821014 SCORE: 0.7236766815185547\n",
      "25/100 => [TRAIN] LOSS: 0.049240916073322295 SCORE: 0.25913634777069094\n",
      "\t=> [VAL] LOSS: 0.15214446187019348 SCORE: 0.7643036246299744\n",
      "26/100 => [TRAIN] LOSS: 0.04091962856742052 SCORE: 0.26209975664432233\n",
      "\t=> [VAL] LOSS: 0.12936393916606903 SCORE: 0.7995943427085876\n",
      "27/100 => [TRAIN] LOSS: 0.03398905142589852 SCORE: 0.26333734503498785\n",
      "\t=> [VAL] LOSS: 0.10987759381532669 SCORE: 0.8297818303108215\n",
      "28/100 => [TRAIN] LOSS: 0.02829854004085064 SCORE: 0.26300654241016935\n",
      "\t=> [VAL] LOSS: 0.09349871426820755 SCORE: 0.855155348777771\n",
      "29/100 => [TRAIN] LOSS: 0.023700057175652735 SCORE: 0.2613022368529747\n",
      "\t=> [VAL] LOSS: 0.08014728873968124 SCORE: 0.8758388757705688\n",
      "30/100 => [TRAIN] LOSS: 0.020036496967077256 SCORE: 0.2584627370039622\n",
      "\t=> [VAL] LOSS: 0.06958835572004318 SCORE: 0.8921964168548584\n",
      "31/100 => [TRAIN] LOSS: 0.017164899697226864 SCORE: 0.2547011298518027\n",
      "\t=> [VAL] LOSS: 0.061620086431503296 SCORE: 0.9045405387878418\n",
      "32/100 => [TRAIN] LOSS: 0.01492942578624934 SCORE: 0.25026487931609154\n",
      "\t=> [VAL] LOSS: 0.05556950718164444 SCORE: 0.9139138460159302\n",
      "33/100 => [TRAIN] LOSS: 0.013208366761153395 SCORE: 0.24531735795916934\n",
      "\t=> [VAL] LOSS: 0.05099085345864296 SCORE: 0.9210069179534912\n",
      "34/100 => [TRAIN] LOSS: 0.011910524328841883 SCORE: 0.24000143654206219\n",
      "\t=> [VAL] LOSS: 0.04794561490416527 SCORE: 0.9257245063781738\n",
      "35/100 => [TRAIN] LOSS: 0.010907509231141635 SCORE: 0.2345514007977077\n",
      "\t=> [VAL] LOSS: 0.04583815485239029 SCORE: 0.9289892911911011\n",
      "36/100 => [TRAIN] LOSS: 0.010132712208562426 SCORE: 0.22904118729962242\n",
      "\t=> [VAL] LOSS: 0.04435816779732704 SCORE: 0.9312820434570312\n",
      "37/100 => [TRAIN] LOSS: 0.00953311609053934 SCORE: 0.22354637287758491\n",
      "\t=> [VAL] LOSS: 0.04338286072015762 SCORE: 0.9327929019927979\n",
      "38/100 => [TRAIN] LOSS: 0.009063289059620155 SCORE: 0.21813392011742844\n",
      "\t=> [VAL] LOSS: 0.04289207234978676 SCORE: 0.9335532188415527\n",
      "39/100 => [TRAIN] LOSS: 0.00867906384743177 SCORE: 0.21287433000711295\n",
      "\t=> [VAL] LOSS: 0.042669154703617096 SCORE: 0.9338985681533813\n",
      "40/100 => [TRAIN] LOSS: 0.008354725036770105 SCORE: 0.20779111385345458\n",
      "\t=> [VAL] LOSS: 0.04249761253595352 SCORE: 0.9341643452644348\n",
      "41/100 => [TRAIN] LOSS: 0.008081533923381713 SCORE: 0.2028771987775477\n",
      "\t=> [VAL] LOSS: 0.042493440210819244 SCORE: 0.9341707825660706\n",
      "42/100 => [TRAIN] LOSS: 0.007834935117335547 SCORE: 0.1981667180856069\n",
      "\t=> [VAL] LOSS: 0.0424884594976902 SCORE: 0.9341784715652466\n",
      "43/100 => [TRAIN] LOSS: 0.007612269674969274 SCORE: 0.19364511273628057\n",
      "\t=> [VAL] LOSS: 0.042471516877412796 SCORE: 0.9342047572135925\n",
      "44/100 => [TRAIN] LOSS: 0.007413166236471046 SCORE: 0.18929682942953976\n",
      "\t=> [VAL] LOSS: 0.042580969631671906 SCORE: 0.9340351819992065\n",
      "45/100 => [TRAIN] LOSS: 0.007217731657955382 SCORE: 0.18514725499682957\n",
      "\t=> [VAL] LOSS: 0.042662013322114944 SCORE: 0.9339096546173096\n",
      "46/100 => [TRAIN] LOSS: 0.0070267429008432055 SCORE: 0.18118046288904938\n",
      "\t=> [VAL] LOSS: 0.042580146342515945 SCORE: 0.9340364933013916\n",
      "47/100 => [TRAIN] LOSS: 0.006858843121122807 SCORE: 0.17735259456837432\n",
      "\t=> [VAL] LOSS: 0.04246610030531883 SCORE: 0.9342131614685059\n",
      "48/100 => [TRAIN] LOSS: 0.006712374122192462 SCORE: 0.17365865409374237\n",
      "\t=> [VAL] LOSS: 0.04257643222808838 SCORE: 0.93404221534729\n",
      "49/100 => [TRAIN] LOSS: 0.006563180107243207 SCORE: 0.17014810990314094\n",
      "\t=> [VAL] LOSS: 0.04272260144352913 SCORE: 0.9338157773017883\n",
      "50/100 => [TRAIN] LOSS: 0.006415794752538204 SCORE: 0.16678668260574342\n",
      "\t=> [VAL] LOSS: 0.04281342402100563 SCORE: 0.9336750507354736\n",
      "51/100 => [TRAIN] LOSS: 0.006280766033074435 SCORE: 0.16354247986101636\n",
      "\t=> [VAL] LOSS: 0.04288560152053833 SCORE: 0.9335632920265198\n",
      "52/100 => [TRAIN] LOSS: 0.00615262627028502 SCORE: 0.16042145398946908\n",
      "\t=> [VAL] LOSS: 0.043009012937545776 SCORE: 0.9333720803260803\n",
      "53/100 => [TRAIN] LOSS: 0.006020911459652883 SCORE: 0.15742447128835715\n",
      "\t=> [VAL] LOSS: 0.04296499490737915 SCORE: 0.9334402680397034\n",
      "54/100 => [TRAIN] LOSS: 0.0058999040543481155 SCORE: 0.15453070512524358\n",
      "\t=> [VAL] LOSS: 0.042812708765268326 SCORE: 0.9336761832237244\n",
      "55/100 => [TRAIN] LOSS: 0.00579593645578081 SCORE: 0.15171077251434326\n",
      "\t=> [VAL] LOSS: 0.04297764226794243 SCORE: 0.9334206581115723\n",
      "56/100 => [TRAIN] LOSS: 0.005669811407902411 SCORE: 0.14905606316668646\n",
      "\t=> [VAL] LOSS: 0.04283451661467552 SCORE: 0.9336423873901367\n",
      "성능 및 손실 개선이 없어서 학습 중단\n"
     ]
    }
   ],
   "source": [
    "## 학습의 효과 확인 => 손실값과 성능평가값 저장 필요\n",
    "loss_history, score_history=[[],[]], [[],[]] # train, val\n",
    "\n",
    "\n",
    "## 학습 모니터링/스케쥴링 설정\n",
    "# => loss_history, score_history 활용\n",
    "# => 임계기준 : 10번\n",
    "BREAK_CNT = 0\n",
    "THESHOLD = 9\n",
    "for epoch in range(1, EPOCHS):\n",
    "    # 학습 모드 함수\n",
    "    loss_total, score_total = training()\n",
    "\n",
    "    # 검증 모드 함수\n",
    "    loss_val, score_val = validate()\n",
    "\n",
    "    # 에포크당 손실값과 성능평가값 저장\n",
    "    loss_history[0].append(loss_total/epoch)\n",
    "    score_history[0].append(score_total/epoch)\n",
    "\n",
    "    loss_history[1].append(loss_val)\n",
    "    score_history[1].append(score_val)\n",
    "\n",
    "    # 학습 진행 모니터링/스케쥴링: - 검증 DS 기준\n",
    "\n",
    "    # Loss 기준\n",
    "    if len(loss_history[1]) >= 2:\n",
    "        if loss_history[1][-1] >= loss_history[1][-2]: BREAK_CNT += 1\n",
    "        \n",
    "    # # score 기준\n",
    "    # if len(score_history[1]) >= 2:\n",
    "    #     if score_history[1][-1] <= score_history[1][-2]: BREAK_CNT += 1\n",
    "\n",
    "    # 학습 중단 여부 설정\n",
    "    if BREAK_CNT >= THESHOLD:\n",
    "        print('성능 및 손실 개선이 없어서 학습 중단')\n",
    "        break\n",
    "\n",
    "    print(f'{epoch}/{EPOCHS} => [TRAIN] LOSS: {loss_history[0][-1]} SCORE: {score_history[0][-1]}')\n",
    "    print(f'\\t=> [VAL] LOSS: {loss_history[1][-1]} SCORE: {score_history[1][-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[테스트 & 검증 상태]\n",
    "- 설정된 W,b 검증 및 테스트용 데이터셋 예측값 추출\n",
    "- 사용되지 않는 기능들 OFF\n",
    "- W, b 업데이트 X\n",
    "    * -> 기능 OFF Auto_grade 엔진 ---> model.eval()\n",
    "    * -> W, b 텐서 required_grade=True ---> no.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] LOSS: 0.04896678775548935 \n",
      "\tSCORE: 0.9080376625061035\n"
     ]
    }
   ],
   "source": [
    "# 테스트 진행\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # 테스트 데이터셋\n",
    "    test_featureTS=torch.FloatTensor(testDS.featureDF.values)\n",
    "    test_targetTS=torch.FloatTensor(testDS.targetDF.values)\n",
    "\n",
    "    # 평가\n",
    "    pre_test=model(test_featureTS)\n",
    "\n",
    "    # 손실\n",
    "    loss_test=reg_loss(pre_test, test_targetTS)\n",
    "\n",
    "    # 성능평가\n",
    "    score_test=R2Score()(pre_test, test_targetTS)\n",
    "print(f'[TEST] LOSS: {loss_test} \\n\\tSCORE: {score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 저장 방법 <hr>\n",
    "- 방법1 : 모델 파라미터만 저장\n",
    "- 방법2 : 모델 설계 구조 및 파라미터까지 모두 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 학습된 모델 파라미터 값 확인\n",
    "\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [방법 1] 모델 파라미터 즉, 층별 가중치와 절편들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "### models 폴더 아래 프로젝트 폴더 아래 모델 파일 저장\n",
    "import os\n",
    "\n",
    "# 저장 경로\n",
    "SAVE_PATH='../Models/iris/'\n",
    "\n",
    "# 저장 파일명\n",
    "SAVE_FILE='model_train_wb.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로상 폴더 존재 여부 체크\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)  # 폴더 / 폴더 / ... 하위 폴더까지 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "torch.save(model.state_dict(), SAVE_PATH+SAVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KDP-50\\AppData\\Local\\Temp\\ipykernel_15464\\1767297501.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  wbTS = torch.load(SAVE_FILE)\n"
     ]
    }
   ],
   "source": [
    "# 모델 즉, 가중치와 절편 로딩\n",
    "# [1] 가중치와 절편 객체로 로딩\n",
    "# [2] 모델의 state_dict 속성에 저장\n",
    "\n",
    "# 읽기\n",
    "wbTS = torch.load(SAVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 인스턴스에 저장\n",
    "model.load_state_dict(wbTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 인스턴스에 저장\n",
    "model2 = irisRegModel() # 층마다 W,b 초기화\n",
    "model2.load_state_dict(wbTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irisRegModel(\n",
      "  (in_layer): Linear(in_features=3, out_features=10, bias=True)\n",
      "  (hidden_layer): Linear(in_features=10, out_features=30, bias=True)\n",
      "  (out_layer): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
