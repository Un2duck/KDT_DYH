{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DNN 기반 회귀 모델 구현 + 학습 진행 모니터링\n",
    "- 데이터셋   : iris.csv\n",
    "- 피쳐/속성  : 3개 Sepal_Length, Sepal_width, Petal_Width\n",
    "- 타겟/라벨  : 1개 Petal_\n",
    "- 학습/방법  : 지도학습 -> 회귀\n",
    "- 알고리즘   : 인공신경망(ANN) -> MLP, DNN : 은닉층이 많은 구성\n",
    "- 프레임워크 : Pytorch\n",
    "\n",
    "***\n",
    "\n",
    "- 모니터링\n",
    "    * 기준 : 검증데이터셋의 loss 또는 score\n",
    "    * 평가 : 학습데이터셋의 loss 또는 score와 비교해서 학습 중단여부 결정\n",
    "    * 저장 : 현재까지 진행된 모델의 파라미터(가중치, 절편) 저장 여부 또는 모델 전체 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 관련 모듈 로딩\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.nn.functional as F  \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchmetrics.regression import R2Score, MeanSquaredError\n",
    "from torchinfo import summary\n",
    "\n",
    "# 데이터 관련 모듈 로딩\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch V.:2.4.1\n",
      "pandas V.:2.0.3\n"
     ]
    }
   ],
   "source": [
    "# 활용 패키지 버전 체크\n",
    "print(f'torch V.:{torch.__version__}')\n",
    "print(f'pandas V.:{pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 데이터 로딩\n",
    "DATA_FILE='../Data/iris.csv'\n",
    "\n",
    "### CSV => DataFrame\n",
    "irisDF = pd.read_csv(DATA_FILE, usecols=[0,1,2,3])\n",
    "\n",
    "### 확인\n",
    "irisDF.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 모델 클래스 설계 및 정의 <hr>\n",
    "- 클래스목적 : iris 데이터를 학습 및 추론\n",
    "- 클래스이름 : irisRegModel\n",
    "- 부모클래스 : nn.Module\n",
    "- 매개 변수 : 층별 입출력 개수 고정하기 때문에 필요 x!\n",
    "- 속성 필드 : \n",
    "- 기능 역할 : __ init__() : 모델 구조 설정, forward() : 순방향 학습 <= 오버라이딩(overriding) - [상속 시 가능!]\n",
    "- 클래스구조\n",
    "    * 입력층 : 입력 3개(피쳐)  출력 10개 (퍼셉트론/뉴런 10개 존재)\n",
    "    * 은닉층 : 입력 10개       출력 30개 (퍼셉트론/뉴런 30개 존재)\n",
    "    * 출력층 : 입력 30개       출력 1개 (너비값)\n",
    "\n",
    "- 활성화함수\n",
    "    * 클래스 형태 ==> ex) nn.MESLoss, nn.ReLU ==> __ init__(self) 메서드\n",
    "    * 함수 형태 ==> torch.nn.functional 아래에 ==> forward(self) 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class irisRegModel(nn.Module):\n",
    "\n",
    "    # 모델 구조 구성 및 인스턴스 생성 메서드\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_layer=nn.Linear(3, 10)\n",
    "        self.hidden_layer=nn.Linear(10, 30)\n",
    "        self.out_layer=nn.Linear(30, 1)\n",
    "\n",
    "    # 순방향 학습 진행 메서드\n",
    "    def forward(self, x):\n",
    "        # - 입력층\n",
    "        y = self.in_layer(x)     # y = f1w1 + f2w2 + f3w3 + b ... -> 10개\n",
    "        y = F.relu(y)            # relu -> y 값의 범위 0 <= y\n",
    "        \n",
    "        # - 은닉층 : 10개의 숫자 값(>=0)\n",
    "        y = self.hidden_layer(y) # y = f21w21 + ... + f210w210 , ... -> 30개\n",
    "        y = F.relu(y)            # relu -> y 값의 범위 0 <= y\n",
    "\n",
    "        # - 출력층 : 1개의 숫자 값(>=0)\n",
    "        return self.out_layer(y)        # f31w31 + ... f330w330 + b -> 1개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irisRegModel(\n",
      "  (in_layer): Linear(in_features=3, out_features=10, bias=True)\n",
      "  (hidden_layer): Linear(in_features=10, out_features=30, bias=True)\n",
      "  (out_layer): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## 모델 인스턴스 생성\n",
    "model = irisRegModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "irisRegModel                             [1000, 1]                 --\n",
       "├─Linear: 1-1                            [1000, 10]                40\n",
       "├─Linear: 1-2                            [1000, 30]                330\n",
       "├─Linear: 1-3                            [1000, 1]                 31\n",
       "==========================================================================================\n",
       "Total params: 401\n",
       "Trainable params: 401\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.40\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.33\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.34\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 사용 메모리 정보 확인\n",
    "summary(model, input_size=(1000,3)) # input_size = ,feature 개수)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 데이터셋 클래스 설계 및 정의 <hr>\n",
    "- 데이터셋 : iris.csv\n",
    "- 피쳐_개수 : 3개\n",
    "- 타겟_개수 : 1개\n",
    "- 클래스이름 : IrisDataset\n",
    "- 부모클래스 : utils.data.Dataset\n",
    "- 속성_필드 : featureDF, targetDF, n_rows, n_features\n",
    "- 필수메서드 : \n",
    "    * __ init__(self): 데이터셋 저장 및 전처리, 개발자가 필요한 속성 설정\n",
    "    * __ len__(self): 데이터의 개수 반환\n",
    "    * __ getitem__(self, index): 특정 인덱스의 피쳐와 타겟 반환\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(Dataset):\n",
    "\n",
    "    def __init__(self, featureDF, targetDF):\n",
    "        self.featureDF=featureDF\n",
    "        self.targetDF=targetDF\n",
    "        self.n_rows=featureDF.shape[0]\n",
    "        self.n_features=featureDF.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 텐서화\n",
    "        featureTS=torch.FloatTensor(self.featureDF.iloc[index].values)\n",
    "        targetTS=torch.FloatTensor(self.targetDF.iloc[index].values)\n",
    "        \n",
    "        # 피쳐와 타겟 반환\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터셋 인스턴스 생성\n",
    "\n",
    "# DataFrame에서 피쳐와 타겟 추출\n",
    "featureDF = irisDF[irisDF.columns[:-1]]     # 2D (150, 3)\n",
    "targetDF = irisDF[irisDF.columns[-1:]]      # 2D (150, 1)\n",
    "\n",
    "# - 커스텀데이터셋 인스턴스 생성\n",
    "irisDS=IrisDataset(featureDF, targetDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 학습 준비\n",
    "- 학습 횟수 : EPOCH          <- 처음~ 끝까지 공부하는 단위\n",
    "- 배치 크기 : BATCH_SIZE     <- 한번에 학습할 데이터셋 양\n",
    "- 위치 지정 : DEVICE         <- 탠서 저장 및 실행 위치 (GPU/CPU)\n",
    "- 학 습 률 : LR 가중치와 절편 업데이트 시 경사하강법으로 업데이트 간격 설정 0.001 ~ 0.1 (낮을수록 촘촘히)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_CNT: 15\n"
     ]
    }
   ],
   "source": [
    "### 학습 진행 관련 설정\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 10\n",
    "BATCH_CNT = irisDF.shape[0]//BATCH_SIZE\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR = 0.001\n",
    "\n",
    "print(f'BATCH_CNT: {BATCH_CNT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인스턴스/객체 : 모델, 데이터셋, 최적화, (손실함수), (성능지표)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X_train(shape): (84, 3) (type): <class 'pandas.core.frame.DataFrame'>], X_test: (38, 3), X_val: (28, 3)\n",
      "[y_train(shape): (84, 1) (type): <class 'pandas.core.frame.DataFrame'>], y_test: (38, 1), y_val: (28, 1)\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스 생성\n",
    "model=irisRegModel()\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "X_train, X_test, y_train, y_test = train_test_split(featureDF, targetDF, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=1)\n",
    "print(f'[X_train(shape): {X_train.shape} (type): {type(X_train)}], X_test: {X_test.shape}, X_val: {X_val.shape}')\n",
    "print(f'[y_train(shape): {y_train.shape} (type): {type(y_train)}], y_test: {y_test.shape}, y_val: {y_val.shape}')\n",
    "\n",
    "trainDS=IrisDataset(X_train, y_train)\n",
    "valDS=IrisDataset(X_val, y_val)\n",
    "testDS=IrisDataset(X_test, y_test)\n",
    "\n",
    "# 데이터로더 인스턴스 생성\n",
    "trainDL=DataLoader(trainDS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3]) torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "## [테스트] 데이터로더\n",
    "for feature, target in trainDL:\n",
    "    # print(feature, target)\n",
    "    print(feature.shape, target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 인스턴스 => W,b 텐서 즉, model.parameters() 전달\n",
    "optimizer=optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# 손실함수 인스턴스 => 회귀 : MSE, MAE, RMSE, ...\n",
    "reg_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> 모델 저장 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### models 폴더 아래 프로젝트 폴더 아래 모델 파일 저장\n",
    "import os\n",
    "\n",
    "# 저장 경로\n",
    "SAVE_PATH='../Models/iris/'\n",
    "\n",
    "# 저장 파일명\n",
    "SAVE_FILE='model_train_wb.pth'\n",
    "\n",
    "# 모델 구조 및 파라미터 모두 저장 파일명\n",
    "SAVE_MODEL='model_all.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로상 폴더 존재 여부 체크\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)  # 폴더 / 폴더 / ... 하위 폴더까지 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 모드 함수\n",
    "def training():\n",
    "    # 학습 모드로 모델 설정\n",
    "    model.train()\n",
    "    # 배치 크기 만큼 데이터 로딩해서 학습 진행\n",
    "    loss_total, score_total=0,0\n",
    "    for featureTS, targetTS in trainDL:\n",
    "\n",
    "        # 학습 진행\n",
    "        pre_y=model(featureTS)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss=reg_loss(pre_y, targetTS)\n",
    "        loss_total+=loss.item()\n",
    "        \n",
    "        # 성능평가 계산\n",
    "        score=R2Score()(pre_y, targetTS)\n",
    "        score_total+=score.item()\n",
    "\n",
    "        # 최적화 진행\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss_total, score_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 모드 함수\n",
    "def validate():\n",
    "    # 검증 모드로 모델 설정\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 검증 데이터셋\n",
    "        val_featureTS=torch.FloatTensor(valDS.featureDF.values)\n",
    "        val_targetTS=torch.FloatTensor(valDS.targetDF.values)\n",
    "        \n",
    "        # 평가\n",
    "        pre_val=model(val_featureTS)\n",
    "\n",
    "        # 손실\n",
    "        loss_val=reg_loss(pre_val, val_targetTS)\n",
    "\n",
    "        # 성능평가\n",
    "        score_val=R2Score()(pre_val, val_targetTS)\n",
    "    return loss_val, score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1000 => [TRAIN] LOSS: 0.267515879124403 SCORE: 8.465595126152039\n",
      "\t=> [VAL] LOSS: 0.03739216923713684 SCORE: 0.9420734643936157\n",
      "2/1000 => [TRAIN] LOSS: 0.13351925974711776 SCORE: 4.233369201421738\n",
      "\t=> [VAL] LOSS: 0.03740090876817703 SCORE: 0.9420599341392517\n",
      "3/1000 => [TRAIN] LOSS: 0.0887988917529583 SCORE: 2.8227544029553733\n",
      "\t=> [VAL] LOSS: 0.037388648837804794 SCORE: 0.9420789480209351\n",
      "4/1000 => [TRAIN] LOSS: 0.06651144195348024 SCORE: 2.1172723323106766\n",
      "\t=> [VAL] LOSS: 0.03735643997788429 SCORE: 0.9421288371086121\n",
      "5/1000 => [TRAIN] LOSS: 0.05317486673593521 SCORE: 1.693916428089142\n",
      "\t=> [VAL] LOSS: 0.03737138584256172 SCORE: 0.9421056509017944\n",
      "6/1000 => [TRAIN] LOSS: 0.044181287909547486 SCORE: 1.4118983149528503\n",
      "\t=> [VAL] LOSS: 0.037365227937698364 SCORE: 0.9421152472496033\n",
      "7/1000 => [TRAIN] LOSS: 0.037804940582386086 SCORE: 1.2103650995663233\n",
      "\t=> [VAL] LOSS: 0.03729337453842163 SCORE: 0.9422265291213989\n",
      "8/1000 => [TRAIN] LOSS: 0.033108354546129704 SCORE: 1.0590117275714874\n",
      "\t=> [VAL] LOSS: 0.037359923124313354 SCORE: 0.9421234130859375\n",
      "9/1000 => [TRAIN] LOSS: 0.029309046558207937 SCORE: 0.9416271845499674\n",
      "\t=> [VAL] LOSS: 0.037316348403692245 SCORE: 0.942190945148468\n",
      "10/1000 => [TRAIN] LOSS: 0.026376698538661 SCORE: 0.8474753439426422\n",
      "\t=> [VAL] LOSS: 0.03732844814658165 SCORE: 0.9421721696853638\n",
      "11/1000 => [TRAIN] LOSS: 0.023934809999032455 SCORE: 0.7705365527759899\n",
      "\t=> [VAL] LOSS: 0.03729007765650749 SCORE: 0.9422316551208496\n",
      "12/1000 => [TRAIN] LOSS: 0.021946180301407974 SCORE: 0.7063212841749191\n",
      "\t=> [VAL] LOSS: 0.037314970046281815 SCORE: 0.9421930909156799\n",
      "13/1000 => [TRAIN] LOSS: 0.02020216231735853 SCORE: 0.6521152670566852\n",
      "\t=> [VAL] LOSS: 0.0373082160949707 SCORE: 0.9422035217285156\n",
      "14/1000 => [TRAIN] LOSS: 0.01874096638389996 SCORE: 0.6055859838213239\n",
      "\t=> [VAL] LOSS: 0.03725916147232056 SCORE: 0.9422795176506042\n",
      "15/1000 => [TRAIN] LOSS: 0.017502937465906143 SCORE: 0.565192723274231\n",
      "\t=> [VAL] LOSS: 0.03730068728327751 SCORE: 0.9422152042388916\n",
      "16/1000 => [TRAIN] LOSS: 0.0163627119618468 SCORE: 0.5299748666584492\n",
      "\t=> [VAL] LOSS: 0.03728853911161423 SCORE: 0.9422340393066406\n",
      "17/1000 => [TRAIN] LOSS: 0.015390425591784366 SCORE: 0.4988270507139318\n",
      "\t=> [VAL] LOSS: 0.03727395087480545 SCORE: 0.9422566294670105\n",
      "18/1000 => [TRAIN] LOSS: 0.01452203741711047 SCORE: 0.4711476200156742\n",
      "\t=> [VAL] LOSS: 0.037245381623506546 SCORE: 0.9423008561134338\n",
      "19/1000 => [TRAIN] LOSS: 0.013765628498635794 SCORE: 0.4463372261900651\n",
      "\t=> [VAL] LOSS: 0.03727254644036293 SCORE: 0.9422587752342224\n",
      "20/1000 => [TRAIN] LOSS: 0.013049025507643818 SCORE: 0.4240860193967819\n",
      "\t=> [VAL] LOSS: 0.037266504019498825 SCORE: 0.9422681331634521\n",
      "21/1000 => [TRAIN] LOSS: 0.012421992296973864 SCORE: 0.4039107050214495\n",
      "\t=> [VAL] LOSS: 0.037258002907037735 SCORE: 0.9422813057899475\n",
      "22/1000 => [TRAIN] LOSS: 0.01185158280317079 SCORE: 0.38556435162370856\n",
      "\t=> [VAL] LOSS: 0.03727849945425987 SCORE: 0.942249596118927\n",
      "23/1000 => [TRAIN] LOSS: 0.011320203380740208 SCORE: 0.36884040158727893\n",
      "\t=> [VAL] LOSS: 0.037252288311719894 SCORE: 0.942290186882019\n",
      "성능 및 손실 개선이 없어서 학습 중단\n"
     ]
    }
   ],
   "source": [
    "## 학습의 효과 확인 => 손실값과 성능평가값 저장 필요\n",
    "loss_history, score_history=[[],[]], [[],[]] # train, val\n",
    "\n",
    "\n",
    "## 학습 모니터링/스케쥴링 설정\n",
    "# => loss_history, score_history 활용\n",
    "# => 임계기준 : 10번\n",
    "BREAK_CNT = 0\n",
    "THESHOLD = 9\n",
    "for epoch in range(1, EPOCHS):\n",
    "    # 학습 모드 함수\n",
    "    loss_total, score_total = training()\n",
    "\n",
    "    # 검증 모드 함수\n",
    "    loss_val, score_val = validate()\n",
    "\n",
    "    # 에포크당 손실값과 성능평가값 저장\n",
    "    loss_history[0].append(loss_total/len(trainDL))\n",
    "    score_history[0].append(score_total/len(trainDL))\n",
    "\n",
    "    loss_history[1].append(loss_val)\n",
    "    score_history[1].append(score_val)\n",
    "\n",
    "    # 학습 진행 모니터링/스케쥴링: - 검증 DS 기준\n",
    "\n",
    "    # Loss 기준\n",
    "    if len(loss_history[1]) >= 2:\n",
    "        if loss_history[1][-1] >= loss_history[1][-2]: BREAK_CNT += 1\n",
    "        \n",
    "    # # score 기준\n",
    "    # if len(score_history[1]) >= 2:\n",
    "    #     if score_history[1][-1] <= score_history[1][-2]: BREAK_CNT += 1\n",
    "\n",
    "    # 성능이 좋은 학습 가중치 저장\n",
    "    # SAVE_FILE=f'model_train_wbs_{epoch}_{score_val:3f}.pth'\n",
    "\n",
    "    if len(score_history[1]) == 1:\n",
    "        # 첫번째라서 무조건 모델 파라미터 저장\n",
    "        torch.save(model.state_dict(), SAVE_PATH+SAVE_FILE)\n",
    "        # 모델 전체 저장\n",
    "        torch.save(model, SAVE_PATH+SAVE_MODEL)\n",
    "    else:\n",
    "        if score_history[1][-1] > max(score_history[1][:-1]):\n",
    "            torch.save(model.state_dict(), SAVE_PATH+SAVE_FILE)\n",
    "            torch.save(model, SAVE_PATH+SAVE_FILE)\n",
    "\n",
    "    # 학습 중단 여부 설정\n",
    "    if BREAK_CNT >= THESHOLD:\n",
    "        print('성능 및 손실 개선이 없어서 학습 중단')\n",
    "        break\n",
    "\n",
    "    print(f'{epoch}/{EPOCHS} => [TRAIN] LOSS: {loss_history[0][-1]} SCORE: {score_history[0][-1]}')\n",
    "    print(f'\\t=> [VAL] LOSS: {loss_history[1][-1]} SCORE: {score_history[1][-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[테스트 & 검증 상태]\n",
    "- 설정된 W,b 검증 및 테스트용 데이터셋 예측값 추출\n",
    "- 사용되지 않는 기능들 OFF\n",
    "- W, b 업데이트 X\n",
    "    * -> 기능 OFF Auto_grade 엔진 ---> model.eval()\n",
    "    * -> W, b 텐서 required_grade=True ---> no.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] LOSS: 0.04896678775548935 \n",
      "\tSCORE: 0.9080376625061035\n"
     ]
    }
   ],
   "source": [
    "# 테스트 진행\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # 테스트 데이터셋\n",
    "    test_featureTS=torch.FloatTensor(testDS.featureDF.values)\n",
    "    test_targetTS=torch.FloatTensor(testDS.targetDF.values)\n",
    "\n",
    "    # 평가\n",
    "    pre_test=model(test_featureTS)\n",
    "\n",
    "    # 손실\n",
    "    loss_test=reg_loss(pre_test, test_targetTS)\n",
    "\n",
    "    # 성능평가\n",
    "    score_test=R2Score()(pre_test, test_targetTS)\n",
    "print(f'[TEST] LOSS: {loss_test} \\n\\tSCORE: {score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 저장 방법 <hr>\n",
    "- 방법1 : 모델 파라미터만 저장\n",
    "- 방법2 : 모델 설계 구조 및 파라미터까지 모두 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 학습된 모델 파라미터 값 확인\n",
    "\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [방법 1] 모델 파라미터 즉, 층별 가중치와 절편들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "torch.save(model.state_dict(), SAVE_PATH+SAVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KDP-50\\AppData\\Local\\Temp\\ipykernel_15464\\1767297501.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  wbTS = torch.load(SAVE_FILE)\n"
     ]
    }
   ],
   "source": [
    "# 모델 즉, 가중치와 절편 로딩\n",
    "# [1] 가중치와 절편 객체로 로딩\n",
    "# [2] 모델의 state_dict 속성에 저장\n",
    "\n",
    "# 읽기\n",
    "wbTS = torch.load(SAVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 인스턴스에 저장\n",
    "model.load_state_dict(wbTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 인스턴스에 저장\n",
    "model2 = irisRegModel() # 층마다 W,b 초기화\n",
    "model2.load_state_dict(wbTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irisRegModel(\n",
      "  (in_layer): Linear(in_features=3, out_features=10, bias=True)\n",
      "  (hidden_layer): Linear(in_features=10, out_features=30, bias=True)\n",
      "  (out_layer): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
