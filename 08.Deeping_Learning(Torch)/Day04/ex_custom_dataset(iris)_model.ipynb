{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사용자 정의 데이터셋과 모델과 학습\n",
    "- iris.csv ==> 사용자 정의 데이터셋\n",
    "- DNN 모델 ==> 사용자 정의 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모듈 로딩\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import F1Score\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder       # 타겟 컬럼 수치화\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서 저장 및 실행 위치 설정\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "DATA_FILE = '../Data/iris.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CSV ==> DataFrame\n",
    "irisDF=pd.read_csv(DATA_FILE)\n",
    "irisDF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 컬럼 수치화 ===> LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(irisDF['variety'])\n",
    "irisDF['variety']=encoder.transform(irisDF['variety'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width  variety\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDF.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 사용자 정의 데이터셋 클래스 생성 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# 클래스이름 : 학습용 데이터셋 텐서화 및 전처리\n",
    "# 클래스목적 : CustomDataSet\n",
    "# 부모클래스 : torch.utils.data.DataSet\n",
    "# 매개  변수 : featureDF, targetDF\n",
    "# ----------------------------------------------------------------\n",
    "class CustomDataSet(Dataset):\n",
    "    # 데이터 로딩 및 전처리 진행과 인스턴스 생성 메서드\n",
    "    def __init__(self, featureDF, targetDF):\n",
    "        super().__init__()\n",
    "        self.featureDF=featureDF\n",
    "        self.targetDF=targetDF\n",
    "        self.n_rows=featureDF.shape[0]\n",
    "        self.n_features=featureDF.shape[1]\n",
    "\n",
    "    # 데이터의 개수 반환 메서드\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "    \n",
    "    # 특정 index의 데이터와 타겟 반환 메서드 => Tensor 반환! \n",
    "    def __getitem__(self, idx):\n",
    "        featureTS=torch.FloatTensor(self.featureDF.iloc[idx].values)\n",
    "        targetTS=torch.FloatTensor(self.targetDF.iloc[idx].values)\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 데이터셋 인스턴스 생성 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureDF(shape) => (150, 4), targetDF(shape) => (150, 1)\n"
     ]
    }
   ],
   "source": [
    "featureDF, targetDF = irisDF[irisDF.columns[:-1]], irisDF[[irisDF.columns[-1]]]\n",
    "\n",
    "print(f'featureDF(shape) => {featureDF.shape}, targetDF(shape) => {targetDF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisDS = CustomDataSet(featureDF, targetDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 150)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IRIS 데이터셋 속성\n",
    "irisDS.n_features, irisDS.n_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 데이터로더 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 필요한 것 : Dataset 인스턴스, Batch_size=1(default)\n",
    "irisDL = DataLoader(irisDS, batch_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 모델 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# 모델 이름  : CustomModel\n",
    "# 부모클래스 : nn.Module\n",
    "# 매개 변수  : in_in, out_out, h_inout, h_cnt\n",
    "# 모델 구조\n",
    "# - 입력층 : 입력 4개   출력 10개 AF ReLU\n",
    "# - 은닉층 : 입력 10개  출력 30개 AF ReLU -> (보완) Leaky ReLU\n",
    "# - 출력층 : 입력 30개  출력 3개 AF분류 - 다중 Softmax\n",
    "# ----------------------------------------------------------------------------\n",
    "class CustomModel(nn.Module):\n",
    "\n",
    "    # 모델 구성 및 인스턴스 생성 메서드 (콜백함수 callback func)\n",
    "    def __init__(self):\n",
    "        # 부모클래스 생성\n",
    "        super().__init__()\n",
    "        # 자식클래스의 인스턴스 속성 설정\n",
    "        self.in_layer=nn.Linear(4,10)\n",
    "        self.hidden_layer=nn.Linear(10,30)\n",
    "        self.out_layer=nn.Linear(30,3) # 0과 나머지, 1과 나머지, 2와 나머지\n",
    "    \n",
    "    # 순방향 학습 메서드\n",
    "    def forward(self, x):\n",
    "        y=F.relu(self.in_layer(x))\n",
    "        y=F.relu(self.hidden_layer(y))\n",
    "        return self.out_layer(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomModel(\n",
      "  (in_layer): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (hidden_layer): Linear(in_features=10, out_features=30, bias=True)\n",
      "  (out_layer): Linear(in_features=30, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CustomModel                              [1000, 3]                 --\n",
       "├─Linear: 1-1                            [1000, 10]                50\n",
       "├─Linear: 1-2                            [1000, 30]                330\n",
       "├─Linear: 1-3                            [1000, 3]                 93\n",
       "==========================================================================================\n",
       "Total params: 473\n",
       "Trainable params: 473\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.47\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 0.34\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.36\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 모델 인스턴스 생성\n",
    "model = CustomModel()\n",
    "print(model)\n",
    "summary(model, input_size=(1000,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('in_layer.weight', Parameter containing:\n",
      "tensor([[ 0.3284,  0.0925,  0.2981, -0.4118],\n",
      "        [-0.1391,  0.0050,  0.4125, -0.1782],\n",
      "        [ 0.3224, -0.3045,  0.3904, -0.1500],\n",
      "        [ 0.1432,  0.0217,  0.1639,  0.4144],\n",
      "        [-0.0936, -0.1181, -0.3626,  0.2926],\n",
      "        [-0.3655, -0.2340,  0.3428,  0.0569],\n",
      "        [-0.4390, -0.4713,  0.3761,  0.2694],\n",
      "        [-0.0275,  0.0052,  0.0844,  0.0958],\n",
      "        [-0.1074, -0.2670, -0.4383, -0.2087],\n",
      "        [-0.3256,  0.1404, -0.4229, -0.2343]], requires_grad=True))\n",
      "('in_layer.bias', Parameter containing:\n",
      "tensor([-0.0658,  0.0954,  0.4052,  0.1812, -0.2917,  0.0558,  0.1827,  0.4406,\n",
      "         0.1264,  0.4784], requires_grad=True))\n",
      "('hidden_layer.weight', Parameter containing:\n",
      "tensor([[ 0.0031,  0.0400, -0.0225, -0.1243, -0.2204,  0.1995,  0.0906, -0.0015,\n",
      "          0.0184,  0.0357],\n",
      "        [-0.1512, -0.1420, -0.0401, -0.2096, -0.0757, -0.0433,  0.2070,  0.1649,\n",
      "         -0.0004, -0.0198],\n",
      "        [ 0.0854,  0.1465, -0.1448,  0.1412, -0.0342,  0.1398,  0.2772, -0.2289,\n",
      "         -0.3008,  0.0266],\n",
      "        [ 0.2166,  0.1033,  0.1830,  0.0172,  0.2907,  0.0197,  0.2751,  0.0074,\n",
      "         -0.1646,  0.0997],\n",
      "        [ 0.1818,  0.1240,  0.0724,  0.2793,  0.0397, -0.0056,  0.0972, -0.1578,\n",
      "          0.1277,  0.0907],\n",
      "        [ 0.2571, -0.0344, -0.2904, -0.0117,  0.2213, -0.1271, -0.0216,  0.0653,\n",
      "         -0.1536, -0.0720],\n",
      "        [ 0.2190, -0.1256,  0.2504, -0.0452,  0.0920, -0.1428, -0.0072, -0.2019,\n",
      "          0.0680,  0.1945],\n",
      "        [ 0.0884, -0.0450, -0.2518,  0.2069, -0.2616,  0.1248,  0.0440, -0.2306,\n",
      "          0.2559, -0.2541],\n",
      "        [ 0.1151, -0.0205, -0.1490, -0.1570,  0.0225,  0.2092, -0.0727,  0.1352,\n",
      "          0.0841,  0.3074],\n",
      "        [-0.1220,  0.1320,  0.2059, -0.2976,  0.2166, -0.0224, -0.0287, -0.0772,\n",
      "          0.2078, -0.0302],\n",
      "        [-0.3161,  0.1324, -0.0088,  0.0391, -0.0008,  0.3155,  0.1950,  0.1945,\n",
      "          0.1357,  0.0803],\n",
      "        [-0.1885, -0.2272,  0.2005, -0.1359, -0.1968, -0.2979,  0.0697,  0.2749,\n",
      "         -0.1190, -0.1623],\n",
      "        [ 0.0324,  0.3135,  0.1644,  0.0498,  0.0920,  0.1234,  0.2713,  0.1146,\n",
      "          0.0188,  0.2911],\n",
      "        [-0.0043,  0.1009, -0.0617,  0.2528, -0.0524, -0.2055, -0.2028, -0.2591,\n",
      "         -0.2990,  0.1289],\n",
      "        [-0.3161,  0.2487, -0.2175, -0.0799, -0.3138,  0.3028,  0.0632, -0.1222,\n",
      "         -0.2877, -0.3100],\n",
      "        [-0.1471,  0.1567,  0.3117,  0.0577,  0.1261,  0.1195, -0.0451,  0.0149,\n",
      "         -0.2076, -0.1013],\n",
      "        [-0.0542, -0.1213,  0.0623,  0.2592, -0.2646,  0.2274, -0.1942, -0.3138,\n",
      "          0.2716, -0.1049],\n",
      "        [ 0.2421, -0.1773,  0.0317,  0.1298,  0.0385, -0.2674,  0.2781,  0.2198,\n",
      "          0.2790,  0.2228],\n",
      "        [-0.1272,  0.2554, -0.2088,  0.1615, -0.1692,  0.2520,  0.2485, -0.2370,\n",
      "         -0.1208,  0.0422],\n",
      "        [-0.0984,  0.1916,  0.1248,  0.1641, -0.2340, -0.1935,  0.1397, -0.3130,\n",
      "          0.0129,  0.0769],\n",
      "        [ 0.0714, -0.0150,  0.0116, -0.2826,  0.1667,  0.0174, -0.1439, -0.0870,\n",
      "          0.0394,  0.1009],\n",
      "        [ 0.0455,  0.2790, -0.1839, -0.2337,  0.2610, -0.2441, -0.2574,  0.0628,\n",
      "          0.1186, -0.2972],\n",
      "        [ 0.1065, -0.0256, -0.1256, -0.1382,  0.2158, -0.2719, -0.1547, -0.0546,\n",
      "         -0.2849, -0.1179],\n",
      "        [-0.2476,  0.1002, -0.2123, -0.1817,  0.0707,  0.0380,  0.0845,  0.1167,\n",
      "         -0.2561, -0.1313],\n",
      "        [-0.0189, -0.2567, -0.1616, -0.0253,  0.2668, -0.1031,  0.1123,  0.3066,\n",
      "         -0.0851,  0.0889],\n",
      "        [ 0.2500,  0.1999, -0.1416, -0.0331,  0.2039, -0.3140, -0.2182, -0.0200,\n",
      "          0.2451, -0.1785],\n",
      "        [-0.2734,  0.1481, -0.0510,  0.0151,  0.1115,  0.0374, -0.1986,  0.0952,\n",
      "         -0.2635, -0.3094],\n",
      "        [ 0.1920, -0.0422,  0.0101,  0.0287,  0.1067, -0.2177,  0.2019, -0.0913,\n",
      "         -0.2528, -0.3069],\n",
      "        [ 0.2262, -0.1330, -0.2831,  0.2922,  0.3014,  0.2392, -0.2925, -0.0478,\n",
      "         -0.3120, -0.3013],\n",
      "        [-0.0592, -0.0938,  0.1303,  0.2955,  0.2799, -0.3108,  0.1671,  0.2867,\n",
      "          0.3154, -0.2408]], requires_grad=True))\n",
      "('hidden_layer.bias', Parameter containing:\n",
      "tensor([-0.1573,  0.2590,  0.1941,  0.2633,  0.1991,  0.0169, -0.2515, -0.1949,\n",
      "         0.1350,  0.0633, -0.0912,  0.2986, -0.1698, -0.1506,  0.0671,  0.1481,\n",
      "         0.0351, -0.2499, -0.1964,  0.2574,  0.1421,  0.1413, -0.1559,  0.0486,\n",
      "        -0.2107,  0.1322, -0.1313,  0.0942, -0.2254, -0.0029],\n",
      "       requires_grad=True))\n",
      "('out_layer.weight', Parameter containing:\n",
      "tensor([[ 0.0395,  0.0251,  0.1290,  0.0161, -0.0749,  0.1366, -0.0648, -0.1250,\n",
      "         -0.0542, -0.1505, -0.0201, -0.0935, -0.0529,  0.1195, -0.0550,  0.1470,\n",
      "         -0.1451, -0.0452,  0.0905,  0.1428,  0.1758,  0.1286,  0.1011,  0.0726,\n",
      "          0.1538,  0.0410, -0.0803, -0.1676, -0.0373,  0.0927],\n",
      "        [-0.1470,  0.0776,  0.0684, -0.1552, -0.0054, -0.0336, -0.0824, -0.1130,\n",
      "         -0.1725,  0.1722,  0.0708,  0.0808,  0.0473, -0.0352,  0.1104,  0.0610,\n",
      "         -0.0731,  0.0754,  0.0091,  0.0666,  0.0487,  0.1818,  0.0224, -0.0311,\n",
      "         -0.1663,  0.1580, -0.0178, -0.1754, -0.0385, -0.0181],\n",
      "        [-0.0703,  0.0872, -0.0214, -0.1605, -0.0347,  0.0799,  0.1071, -0.0901,\n",
      "         -0.0544, -0.0748, -0.0501,  0.1057,  0.1753, -0.1065, -0.0871, -0.0645,\n",
      "          0.1143, -0.0875,  0.0437, -0.0932, -0.0825, -0.0811, -0.0875,  0.0626,\n",
      "          0.1644, -0.1353, -0.1120,  0.1356,  0.0872, -0.1707]],\n",
      "       requires_grad=True))\n",
      "('out_layer.bias', Parameter containing:\n",
      "tensor([ 0.0057,  0.1352, -0.0985], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "# 모델 파라미터 즉, W와 b확인\n",
    "for n in model.named_parameters(): print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6] 학습 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델의 가중치와 절편을 최적화 ==> 인스턴스에 전달\n",
    "optim=optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feature] X_TRAIN: (96, 4), X_TEST: (30, 4), X_VAL: (24, 4)\n",
      "[target] Y_TRAIN:(96, 1), Y_TEST: (30, 1), Y_VAL: (24, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(featureDF,\n",
    "                                                    targetDF,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=5)\n",
    "\n",
    "# Train & Valid\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                    y_train,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=5)\n",
    "\n",
    "print(f'[feature] X_TRAIN: {X_train.shape}, X_TEST: {X_test.shape}, X_VAL: {X_val.shape}')\n",
    "print(f'[target] Y_TRAIN:{y_train.shape}, Y_TEST: {y_test.shape}, Y_VAL: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 100, BATCH_SIZE: 10, BATCH_CNT: 9\n"
     ]
    }
   ],
   "source": [
    "EPOCH=100                                       # 처음~끝까지 공부하는 횟수\n",
    "BATCH_SIZE=10                                   # 1 에포크에서 한 번 학습할 분량 크기\n",
    "BATCH_CNT=X_train.shape[0]//BATCH_SIZE          # 1 에포크에서 총 학습 횟수이면서 업데이트 횟수\n",
    "\n",
    "print(f'EPOCH: {EPOCH}, BATCH_SIZE: {BATCH_SIZE}, BATCH_CNT: {BATCH_CNT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# 함수기능 : 검증 및 테스트 진행 후 손실값과 성능지표값 반환 함수\n",
    "# 함수이름 : testing\n",
    "# 매개변수 : val_feature, val_target\n",
    "# 반 환 값 : 손실값과 성능지표값\n",
    "# ----------------------------------------------------------------\n",
    "def testing(val_feature, val_target):\n",
    "    # Tensor화\n",
    "    val_feature = torch.FloatTensor(val_feature.values).to(DEVICE)\n",
    "    val_target = torch.FloatTensor(val_target.values).to(DEVICE)\n",
    "    val_target = val_target.reshape(-1).long()\n",
    "    with torch.no_grad():\n",
    "        # 학습 진행\n",
    "        pre_y = model(val_feature)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss=nn.CrossEntropyLoss()(pre_y, val_target)\n",
    "\n",
    "        # 점수 추출\n",
    "        score = F1Score(task=\"multiclass\", num_classes=3)(pre_y, val_target)\n",
    "\n",
    "    # 손실값과 성능지표값 반환\n",
    "    return loss, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# 함수기능 : 학습 진행 후 손실값과 성능지표값 반환 함수\n",
    "# 함수이름 : training\n",
    "# 매개변수 : model, dataTS, targetTS, batch_cnt, batch_size=3\n",
    "# 반 환 값 : 에포크당 손실값과 성능지표값\n",
    "# ----------------------------------------------------------------\n",
    "def training(model, dataTS, targetTS, batch_cnt, batch_size=3):\n",
    "    ## 데이터의 타겟 추출해서 학습 진행\n",
    "    loss_history=[[],[]]\n",
    "    F1_history=[[],[]]\n",
    "\n",
    "    for epoch in range(batch_cnt):\n",
    "\n",
    "        # 배치 손실 저장 변수\n",
    "        loss_total, score_total = 0,0\n",
    "        for dataTS, targetTS in irisDL:\n",
    "            \n",
    "            # (확인용) 배치크기 만큼의 학습 데이터\n",
    "            # print(dataTS.shape, targetTS.shape)\n",
    "            targetTS=targetTS.reshape(-1).long()\n",
    "            # print(dataTS.shape, targetTS.shape)\n",
    "\n",
    "            # (1) 배치 크기만큼 학습 진행\n",
    "            pre_y = model(dataTS)\n",
    "            # print(pre_y.shape, targetTS.reshape(-1).shape)\n",
    "            \n",
    "            # (2) 손실 계산\n",
    "            loss=nn.CrossEntropyLoss()(pre_y, targetTS)\n",
    "            loss_total += loss.detach().numpy()\n",
    "            \n",
    "            # 점수 추출\n",
    "            score = F1Score(task=\"multiclass\", num_classes=3)(pre_y, targetTS)\n",
    "            score_total += score.detach().numpy()\n",
    "            \n",
    "            # 최적화 - 가중치(W), 절편(b) 업데이트\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        \n",
    "        # 검증 - 모델이 제대로 만들어지는 검사용\n",
    "        val_loss, val_F1 = testing(X_val, y_val)\n",
    "        loss_history[1].append(val_loss.item())\n",
    "        F1_history[1].append(val_F1.item())\n",
    "\n",
    "        # 에포크 단위 손실과 성능지표\n",
    "        loss_history[0].append(loss_total/BATCH_CNT)\n",
    "        F1_history[0].append(score_total/BATCH_CNT)\n",
    "\n",
    "        # 학습결과 출력 및 저장\n",
    "        print(f'[{epoch}/{batch_cnt}] \\n TRAIN LOSS : {loss_history[0][-1]}, F1 : {F1_history[0][-1]}')\n",
    "        print(f'VAL LOSS : {loss_history[1][-1]}, F1 : {F1_history[1][-1]}')\n",
    "\n",
    "    # 에포크당 손실값과 성능지표값 반환\n",
    "    return loss_history, F1_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/1000] \n",
      " TRAIN LOSS : 8.554092526435852, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[1/1000] \n",
      " TRAIN LOSS : 8.554092360867394, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[2/1000] \n",
      " TRAIN LOSS : 8.554092526435852, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[3/1000] \n",
      " TRAIN LOSS : 8.554092360867394, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[4/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[5/1000] \n",
      " TRAIN LOSS : 8.554092473453945, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[6/1000] \n",
      " TRAIN LOSS : 8.554092254903582, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[7/1000] \n",
      " TRAIN LOSS : 8.554092254903582, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[8/1000] \n",
      " TRAIN LOSS : 8.554092473453945, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[9/1000] \n",
      " TRAIN LOSS : 8.554092241658104, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[10/1000] \n",
      " TRAIN LOSS : 8.554092201921675, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[11/1000] \n",
      " TRAIN LOSS : 8.554092367490133, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[12/1000] \n",
      " TRAIN LOSS : 8.554092162185245, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[13/1000] \n",
      " TRAIN LOSS : 8.554092201921675, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[14/1000] \n",
      " TRAIN LOSS : 8.554092367490133, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[15/1000] \n",
      " TRAIN LOSS : 8.554092162185245, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[16/1000] \n",
      " TRAIN LOSS : 8.554092201921675, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[17/1000] \n",
      " TRAIN LOSS : 8.554092367490133, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[18/1000] \n",
      " TRAIN LOSS : 8.554092162185245, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[19/1000] \n",
      " TRAIN LOSS : 8.55409229464001, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[20/1000] \n",
      " TRAIN LOSS : 8.55409249332216, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[21/1000] \n",
      " TRAIN LOSS : 8.554092076089647, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[22/1000] \n",
      " TRAIN LOSS : 8.554092281394535, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[23/1000] \n",
      " TRAIN LOSS : 8.554092168807983, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[24/1000] \n",
      " TRAIN LOSS : 8.554092281394535, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[25/1000] \n",
      " TRAIN LOSS : 8.554092168807983, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[26/1000] \n",
      " TRAIN LOSS : 8.55409206946691, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[27/1000] \n",
      " TRAIN LOSS : 8.554092029730478, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[28/1000] \n",
      " TRAIN LOSS : 8.55409206946691, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[29/1000] \n",
      " TRAIN LOSS : 8.554092029730478, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[30/1000] \n",
      " TRAIN LOSS : 8.55409206946691, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[31/1000] \n",
      " TRAIN LOSS : 8.554092029730478, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[32/1000] \n",
      " TRAIN LOSS : 8.554092109203339, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[33/1000] \n",
      " TRAIN LOSS : 8.554091996616787, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[34/1000] \n",
      " TRAIN LOSS : 8.554092095957863, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[35/1000] \n",
      " TRAIN LOSS : 8.554092109203339, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[36/1000] \n",
      " TRAIN LOSS : 8.554092195298937, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[37/1000] \n",
      " TRAIN LOSS : 8.55409218205346, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[38/1000] \n",
      " TRAIN LOSS : 8.554092155562508, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[39/1000] \n",
      " TRAIN LOSS : 8.554092155562508, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[40/1000] \n",
      " TRAIN LOSS : 8.554092168807983, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[41/1000] \n",
      " TRAIN LOSS : 8.554092168807983, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[42/1000] \n",
      " TRAIN LOSS : 8.55409214231703, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[43/1000] \n",
      " TRAIN LOSS : 8.554092076089647, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[44/1000] \n",
      " TRAIN LOSS : 8.554092076089647, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[45/1000] \n",
      " TRAIN LOSS : 8.554091758198208, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[46/1000] \n",
      " TRAIN LOSS : 8.55409183104833, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[47/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[48/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[49/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[50/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[51/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[52/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[53/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[54/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[55/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[56/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[57/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[58/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[59/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[60/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[61/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[62/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[63/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[64/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[65/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[66/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[67/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[68/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[69/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[70/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[71/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[72/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[73/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[74/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[75/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[76/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[77/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[78/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[79/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[80/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[81/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[82/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[83/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[84/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[85/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[86/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[87/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[88/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[89/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[90/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[91/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[92/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[93/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[94/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[95/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[96/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[97/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[98/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[99/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[100/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[101/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[102/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[103/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[104/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[105/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[106/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[107/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[108/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[109/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[110/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[111/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[112/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[113/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[114/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[115/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[116/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[117/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[118/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[119/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[120/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[121/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[122/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[123/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[124/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[125/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[126/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[127/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[128/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[129/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[130/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[131/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[132/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[133/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[134/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[135/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[136/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[137/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[138/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[139/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[140/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[141/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[142/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[143/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[144/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[145/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[146/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[147/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[148/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[149/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[150/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[151/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[152/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[153/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[154/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[155/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[156/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[157/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[158/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[159/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[160/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[161/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[162/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[163/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[164/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[165/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[166/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[167/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[168/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[169/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[170/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[171/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[172/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[173/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[174/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[175/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[176/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[177/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[178/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[179/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[180/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[181/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[182/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[183/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[184/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[185/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[186/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[187/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[188/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[189/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[190/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[191/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[192/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[193/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[194/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[195/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[196/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[197/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[198/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[199/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[200/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[201/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[202/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[203/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[204/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[205/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[206/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[207/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[208/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[209/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[210/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[211/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[212/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[213/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[214/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[215/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[216/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[217/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[218/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[219/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[220/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[221/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[222/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[223/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[224/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[225/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[226/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[227/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[228/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[229/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[230/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[231/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[232/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[233/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[234/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[235/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[236/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[237/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[238/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[239/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[240/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[241/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[242/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[243/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[244/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[245/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[246/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[247/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[248/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[249/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[250/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[251/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[252/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[253/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[254/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[255/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[256/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[257/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[258/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[259/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[260/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[261/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[262/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[263/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[264/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[265/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[266/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[267/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[268/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[269/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[270/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[271/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[272/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[273/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[274/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[275/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[276/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[277/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[278/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[279/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[280/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[281/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[282/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[283/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[284/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[285/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[286/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[287/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[288/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[289/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[290/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[291/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[292/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[293/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[294/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[295/1000] \n",
      " TRAIN LOSS : 8.554092268149057, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[296/1000] \n",
      " TRAIN LOSS : 8.554091393947601, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[297/1000] \n",
      " TRAIN LOSS : 8.554091890652975, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[298/1000] \n",
      " TRAIN LOSS : 8.5540914800432, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[299/1000] \n",
      " TRAIN LOSS : 8.554092029730478, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[300/1000] \n",
      " TRAIN LOSS : 8.554091599252489, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[301/1000] \n",
      " TRAIN LOSS : 8.554092049598694, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[302/1000] \n",
      " TRAIN LOSS : 8.5540917913119, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[303/1000] \n",
      " TRAIN LOSS : 8.554091612497965, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[304/1000] \n",
      " TRAIN LOSS : 8.554091599252489, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[305/1000] \n",
      " TRAIN LOSS : 8.554091599252489, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[306/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[307/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[308/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[309/1000] \n",
      " TRAIN LOSS : 8.554091533025106, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[310/1000] \n",
      " TRAIN LOSS : 8.554091533025106, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[311/1000] \n",
      " TRAIN LOSS : 8.554091327720219, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[312/1000] \n",
      " TRAIN LOSS : 8.55409175157547, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[313/1000] \n",
      " TRAIN LOSS : 8.554092003239525, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[314/1000] \n",
      " TRAIN LOSS : 8.554091023074257, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[315/1000] \n",
      " TRAIN LOSS : 8.554091718461779, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[316/1000] \n",
      " TRAIN LOSS : 8.554091844293806, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[317/1000] \n",
      " TRAIN LOSS : 8.554091705216301, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[318/1000] \n",
      " TRAIN LOSS : 8.554090956846872, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[319/1000] \n",
      " TRAIN LOSS : 8.554091705216301, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[320/1000] \n",
      " TRAIN LOSS : 8.554090956846872, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[321/1000] \n",
      " TRAIN LOSS : 8.554091705216301, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[322/1000] \n",
      " TRAIN LOSS : 8.554090956846872, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[323/1000] \n",
      " TRAIN LOSS : 8.55409167872535, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[324/1000] \n",
      " TRAIN LOSS : 8.554090936978659, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[325/1000] \n",
      " TRAIN LOSS : 8.554091473420462, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[326/1000] \n",
      " TRAIN LOSS : 8.554091427061293, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[327/1000] \n",
      " TRAIN LOSS : 8.554091261492836, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[328/1000] \n",
      " TRAIN LOSS : 8.554090804523891, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[329/1000] \n",
      " TRAIN LOSS : 8.554091473420462, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[330/1000] \n",
      " TRAIN LOSS : 8.554091427061293, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[331/1000] \n",
      " TRAIN LOSS : 8.554091261492836, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[332/1000] \n",
      " TRAIN LOSS : 8.55409034093221, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[333/1000] \n",
      " TRAIN LOSS : 8.554091592629751, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[334/1000] \n",
      " TRAIN LOSS : 8.554090513123406, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[335/1000] \n",
      " TRAIN LOSS : 8.554091023074257, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[336/1000] \n",
      " TRAIN LOSS : 8.554090513123406, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[337/1000] \n",
      " TRAIN LOSS : 8.554091023074257, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[338/1000] \n",
      " TRAIN LOSS : 8.554090513123406, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[339/1000] \n",
      " TRAIN LOSS : 8.554091023074257, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[340/1000] \n",
      " TRAIN LOSS : 8.554090725051033, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[341/1000] \n",
      " TRAIN LOSS : 8.554091036319733, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[342/1000] \n",
      " TRAIN LOSS : 8.554091221756405, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[343/1000] \n",
      " TRAIN LOSS : 8.554090599219004, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[344/1000] \n",
      " TRAIN LOSS : 8.554091221756405, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[345/1000] \n",
      " TRAIN LOSS : 8.554090744919247, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[346/1000] \n",
      " TRAIN LOSS : 8.554091327720219, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[347/1000] \n",
      " TRAIN LOSS : 8.554090744919247, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[348/1000] \n",
      " TRAIN LOSS : 8.554091327720219, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[349/1000] \n",
      " TRAIN LOSS : 8.554090744919247, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[350/1000] \n",
      " TRAIN LOSS : 8.554091327720219, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[351/1000] \n",
      " TRAIN LOSS : 8.554090744919247, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[352/1000] \n",
      " TRAIN LOSS : 8.554091625743443, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[353/1000] \n",
      " TRAIN LOSS : 8.554090989960564, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[354/1000] \n",
      " TRAIN LOSS : 8.554091427061293, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[355/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[356/1000] \n",
      " TRAIN LOSS : 8.554091427061293, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[357/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[358/1000] \n",
      " TRAIN LOSS : 8.554091427061293, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[359/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[360/1000] \n",
      " TRAIN LOSS : 8.554091427061293, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[361/1000] \n",
      " TRAIN LOSS : 8.554090837637583, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[362/1000] \n",
      " TRAIN LOSS : 8.554090943601397, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[363/1000] \n",
      " TRAIN LOSS : 8.554090837637583, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[364/1000] \n",
      " TRAIN LOSS : 8.55409030781852, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[365/1000] \n",
      " TRAIN LOSS : 8.554090645578173, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[366/1000] \n",
      " TRAIN LOSS : 8.554090837637583, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[367/1000] \n",
      " TRAIN LOSS : 8.55409038066864, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[368/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[369/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[370/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[371/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[372/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[373/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[374/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[375/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[376/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[377/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[378/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[379/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[380/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[381/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[382/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[383/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[384/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[385/1000] \n",
      " TRAIN LOSS : 8.554090864128536, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[386/1000] \n",
      " TRAIN LOSS : 8.554090864128536, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[387/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[388/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[389/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[390/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[391/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[392/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[393/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[394/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[395/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[396/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[397/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[398/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[399/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[400/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[401/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[402/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[403/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[404/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[405/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[406/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[407/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[408/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[409/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[410/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[411/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[412/1000] \n",
      " TRAIN LOSS : 8.554090725051033, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[413/1000] \n",
      " TRAIN LOSS : 8.554090725051033, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[414/1000] \n",
      " TRAIN LOSS : 8.554090725051033, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[415/1000] \n",
      " TRAIN LOSS : 8.554090725051033, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[416/1000] \n",
      " TRAIN LOSS : 8.554090725051033, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[417/1000] \n",
      " TRAIN LOSS : 8.554090725051033, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[418/1000] \n",
      " TRAIN LOSS : 8.554090725051033, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[419/1000] \n",
      " TRAIN LOSS : 8.554090725051033, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[420/1000] \n",
      " TRAIN LOSS : 8.554090599219004, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[421/1000] \n",
      " TRAIN LOSS : 8.554090486632454, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[422/1000] \n",
      " TRAIN LOSS : 8.554090599219004, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[423/1000] \n",
      " TRAIN LOSS : 8.554090486632454, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[424/1000] \n",
      " TRAIN LOSS : 8.554090599219004, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[425/1000] \n",
      " TRAIN LOSS : 8.554091049565208, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[426/1000] \n",
      " TRAIN LOSS : 8.554090599219004, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[427/1000] \n",
      " TRAIN LOSS : 8.554091049565208, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[428/1000] \n",
      " TRAIN LOSS : 8.554090599219004, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[429/1000] \n",
      " TRAIN LOSS : 8.554091049565208, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[430/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[431/1000] \n",
      " TRAIN LOSS : 8.554091049565208, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[432/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[433/1000] \n",
      " TRAIN LOSS : 8.554090831014845, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[434/1000] \n",
      " TRAIN LOSS : 8.554090903864967, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[435/1000] \n",
      " TRAIN LOSS : 8.554091049565208, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[436/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[437/1000] \n",
      " TRAIN LOSS : 8.554090831014845, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[438/1000] \n",
      " TRAIN LOSS : 8.554090903864967, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[439/1000] \n",
      " TRAIN LOSS : 8.554091036319733, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[440/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[441/1000] \n",
      " TRAIN LOSS : 8.554090910487705, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[442/1000] \n",
      " TRAIN LOSS : 8.554090493255192, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[443/1000] \n",
      " TRAIN LOSS : 8.554090546237099, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[444/1000] \n",
      " TRAIN LOSS : 8.554090910487705, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[445/1000] \n",
      " TRAIN LOSS : 8.554090493255192, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[446/1000] \n",
      " TRAIN LOSS : 8.554090546237099, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[447/1000] \n",
      " TRAIN LOSS : 8.554090910487705, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[448/1000] \n",
      " TRAIN LOSS : 8.554090493255192, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[449/1000] \n",
      " TRAIN LOSS : 8.554090546237099, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[450/1000] \n",
      " TRAIN LOSS : 8.554090910487705, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[451/1000] \n",
      " TRAIN LOSS : 8.554090506500668, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[452/1000] \n",
      " TRAIN LOSS : 8.55409057272805, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[453/1000] \n",
      " TRAIN LOSS : 8.554090910487705, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[454/1000] \n",
      " TRAIN LOSS : 8.554090506500668, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[455/1000] \n",
      " TRAIN LOSS : 8.55409057272805, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[456/1000] \n",
      " TRAIN LOSS : 8.554090910487705, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[457/1000] \n",
      " TRAIN LOSS : 8.554090506500668, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[458/1000] \n",
      " TRAIN LOSS : 8.554090162118277, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[459/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[460/1000] \n",
      " TRAIN LOSS : 8.554090162118277, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[461/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[462/1000] \n",
      " TRAIN LOSS : 8.554090162118277, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[463/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[464/1000] \n",
      " TRAIN LOSS : 8.554090162118277, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[465/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[466/1000] \n",
      " TRAIN LOSS : 8.554090162118277, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[467/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[468/1000] \n",
      " TRAIN LOSS : 8.554090162118277, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[469/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[470/1000] \n",
      " TRAIN LOSS : 8.554090162118277, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[471/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[472/1000] \n",
      " TRAIN LOSS : 8.554090287950304, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[473/1000] \n",
      " TRAIN LOSS : 8.554090923733181, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[474/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[475/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[476/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[477/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[478/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[479/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[480/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[481/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[482/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[483/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[484/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[485/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[486/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[487/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[488/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[489/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[490/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[491/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[492/1000] \n",
      " TRAIN LOSS : 8.554090281327566, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[493/1000] \n",
      " TRAIN LOSS : 8.55409018860923, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[494/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[495/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[496/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[497/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[498/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[499/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[500/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[501/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[502/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[503/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[504/1000] \n",
      " TRAIN LOSS : 8.554090797901154, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[505/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[506/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[507/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[508/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[509/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[510/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[511/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[512/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[513/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[514/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[515/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[516/1000] \n",
      " TRAIN LOSS : 8.554091082678902, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[517/1000] \n",
      " TRAIN LOSS : 8.554089738263023, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[518/1000] \n",
      " TRAIN LOSS : 8.55409042040507, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[519/1000] \n",
      " TRAIN LOSS : 8.554091082678902, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[520/1000] \n",
      " TRAIN LOSS : 8.554089738263023, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[521/1000] \n",
      " TRAIN LOSS : 8.554090480009714, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[522/1000] \n",
      " TRAIN LOSS : 8.554091082678902, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[523/1000] \n",
      " TRAIN LOSS : 8.554089738263023, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[524/1000] \n",
      " TRAIN LOSS : 8.554090480009714, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[525/1000] \n",
      " TRAIN LOSS : 8.554091082678902, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[526/1000] \n",
      " TRAIN LOSS : 8.554089738263023, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[527/1000] \n",
      " TRAIN LOSS : 8.554090532991621, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[528/1000] \n",
      " TRAIN LOSS : 8.554090215100182, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[529/1000] \n",
      " TRAIN LOSS : 8.554089804490408, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[530/1000] \n",
      " TRAIN LOSS : 8.554090532991621, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[531/1000] \n",
      " TRAIN LOSS : 8.554090215100182, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[532/1000] \n",
      " TRAIN LOSS : 8.554089804490408, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[533/1000] \n",
      " TRAIN LOSS : 8.554090532991621, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[534/1000] \n",
      " TRAIN LOSS : 8.554090215100182, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[535/1000] \n",
      " TRAIN LOSS : 8.554089817735884, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[536/1000] \n",
      " TRAIN LOSS : 8.554090532991621, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[537/1000] \n",
      " TRAIN LOSS : 8.554090215100182, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[538/1000] \n",
      " TRAIN LOSS : 8.554089817735884, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[539/1000] \n",
      " TRAIN LOSS : 8.554090532991621, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[540/1000] \n",
      " TRAIN LOSS : 8.554090215100182, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[541/1000] \n",
      " TRAIN LOSS : 8.554089817735884, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[542/1000] \n",
      " TRAIN LOSS : 8.554090532991621, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[543/1000] \n",
      " TRAIN LOSS : 8.554090215100182, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[544/1000] \n",
      " TRAIN LOSS : 8.554089817735884, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[545/1000] \n",
      " TRAIN LOSS : 8.554090532991621, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[546/1000] \n",
      " TRAIN LOSS : 8.554090215100182, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[547/1000] \n",
      " TRAIN LOSS : 8.554089817735884, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[548/1000] \n",
      " TRAIN LOSS : 8.554090519746145, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[549/1000] \n",
      " TRAIN LOSS : 8.554090215100182, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[550/1000] \n",
      " TRAIN LOSS : 8.554089817735884, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[551/1000] \n",
      " TRAIN LOSS : 8.554090493255192, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[552/1000] \n",
      " TRAIN LOSS : 8.554090347554949, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[553/1000] \n",
      " TRAIN LOSS : 8.554090347554949, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[554/1000] \n",
      " TRAIN LOSS : 8.554090347554949, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[555/1000] \n",
      " TRAIN LOSS : 8.554090347554949, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[556/1000] \n",
      " TRAIN LOSS : 8.554090347554949, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[557/1000] \n",
      " TRAIN LOSS : 8.554090347554949, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[558/1000] \n",
      " TRAIN LOSS : 8.554090347554949, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[559/1000] \n",
      " TRAIN LOSS : 8.554090347554949, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[560/1000] \n",
      " TRAIN LOSS : 8.554090347554949, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[561/1000] \n",
      " TRAIN LOSS : 8.554090347554949, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[562/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[563/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[564/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[565/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[566/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[567/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[568/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[569/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[570/1000] \n",
      " TRAIN LOSS : 8.554090519746145, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[571/1000] \n",
      " TRAIN LOSS : 8.554090519746145, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[572/1000] \n",
      " TRAIN LOSS : 8.554090519746145, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[573/1000] \n",
      " TRAIN LOSS : 8.554090519746145, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[574/1000] \n",
      " TRAIN LOSS : 8.554090519746145, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[575/1000] \n",
      " TRAIN LOSS : 8.554090427027809, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[576/1000] \n",
      " TRAIN LOSS : 8.554090427027809, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[577/1000] \n",
      " TRAIN LOSS : 8.554090413782331, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[578/1000] \n",
      " TRAIN LOSS : 8.554090413782331, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[579/1000] \n",
      " TRAIN LOSS : 8.554090413782331, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[580/1000] \n",
      " TRAIN LOSS : 8.554090413782331, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[581/1000] \n",
      " TRAIN LOSS : 8.554090413782331, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[582/1000] \n",
      " TRAIN LOSS : 8.554090413782331, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[583/1000] \n",
      " TRAIN LOSS : 8.554090413782331, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[584/1000] \n",
      " TRAIN LOSS : 8.554090413782331, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[585/1000] \n",
      " TRAIN LOSS : 8.554090413782331, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[586/1000] \n",
      " TRAIN LOSS : 8.554090413782331, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[587/1000] \n",
      " TRAIN LOSS : 8.554090413782331, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[588/1000] \n",
      " TRAIN LOSS : 8.554090413782331, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[589/1000] \n",
      " TRAIN LOSS : 8.554090413782331, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[590/1000] \n",
      " TRAIN LOSS : 8.554090413782331, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[591/1000] \n",
      " TRAIN LOSS : 8.554090413782331, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[592/1000] \n",
      " TRAIN LOSS : 8.554090943601397, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[593/1000] \n",
      " TRAIN LOSS : 8.554089579317305, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[594/1000] \n",
      " TRAIN LOSS : 8.554090784655678, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[595/1000] \n",
      " TRAIN LOSS : 8.554090532991621, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[596/1000] \n",
      " TRAIN LOSS : 8.554090532991621, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[597/1000] \n",
      " TRAIN LOSS : 8.554090532991621, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[598/1000] \n",
      " TRAIN LOSS : 8.554090632332695, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[599/1000] \n",
      " TRAIN LOSS : 8.554090672069126, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[600/1000] \n",
      " TRAIN LOSS : 8.554090672069126, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[601/1000] \n",
      " TRAIN LOSS : 8.554090672069126, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[602/1000] \n",
      " TRAIN LOSS : 8.554090672069126, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[603/1000] \n",
      " TRAIN LOSS : 8.554090672069126, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[604/1000] \n",
      " TRAIN LOSS : 8.554090672069126, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[605/1000] \n",
      " TRAIN LOSS : 8.554090672069126, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[606/1000] \n",
      " TRAIN LOSS : 8.554090672069126, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[607/1000] \n",
      " TRAIN LOSS : 8.554090672069126, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[608/1000] \n",
      " TRAIN LOSS : 8.554090672069126, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[609/1000] \n",
      " TRAIN LOSS : 8.554090672069126, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[610/1000] \n",
      " TRAIN LOSS : 8.554090672069126, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[611/1000] \n",
      " TRAIN LOSS : 8.554090831014845, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[612/1000] \n",
      " TRAIN LOSS : 8.554090831014845, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[613/1000] \n",
      " TRAIN LOSS : 8.554090354177687, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[614/1000] \n",
      " TRAIN LOSS : 8.554090393914116, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[615/1000] \n",
      " TRAIN LOSS : 8.55409112241533, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[616/1000] \n",
      " TRAIN LOSS : 8.554090791278416, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[617/1000] \n",
      " TRAIN LOSS : 8.554090354177687, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[618/1000] \n",
      " TRAIN LOSS : 8.554090393914116, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[619/1000] \n",
      " TRAIN LOSS : 8.55409112241533, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[620/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[621/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[622/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[623/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[624/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[625/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[626/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[627/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[628/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[629/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[630/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[631/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[632/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[633/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[634/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[635/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[636/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[637/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[638/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[639/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[640/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[641/1000] \n",
      " TRAIN LOSS : 8.554090751541985, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[642/1000] \n",
      " TRAIN LOSS : 8.554090751541985, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[643/1000] \n",
      " TRAIN LOSS : 8.554090751541985, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[644/1000] \n",
      " TRAIN LOSS : 8.554090751541985, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[645/1000] \n",
      " TRAIN LOSS : 8.554090751541985, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[646/1000] \n",
      " TRAIN LOSS : 8.554090751541985, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[647/1000] \n",
      " TRAIN LOSS : 8.554090751541985, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[648/1000] \n",
      " TRAIN LOSS : 8.554090751541985, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[649/1000] \n",
      " TRAIN LOSS : 8.554090751541985, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[650/1000] \n",
      " TRAIN LOSS : 8.554090751541985, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[651/1000] \n",
      " TRAIN LOSS : 8.554090751541985, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[652/1000] \n",
      " TRAIN LOSS : 8.554090751541985, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[653/1000] \n",
      " TRAIN LOSS : 8.554090751541985, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[654/1000] \n",
      " TRAIN LOSS : 8.554090751541985, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[655/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[656/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[657/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[658/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[659/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[660/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[661/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[662/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[663/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[664/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[665/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[666/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[667/1000] \n",
      " TRAIN LOSS : 8.55409073167377, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[668/1000] \n",
      " TRAIN LOSS : 8.554090718428293, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[669/1000] \n",
      " TRAIN LOSS : 8.554090718428293, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[670/1000] \n",
      " TRAIN LOSS : 8.554090718428293, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[671/1000] \n",
      " TRAIN LOSS : 8.554090718428293, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[672/1000] \n",
      " TRAIN LOSS : 8.554091115792593, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[673/1000] \n",
      " TRAIN LOSS : 8.554091115792593, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[674/1000] \n",
      " TRAIN LOSS : 8.554091115792593, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[675/1000] \n",
      " TRAIN LOSS : 8.554091076056162, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[676/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[677/1000] \n",
      " TRAIN LOSS : 8.554091076056162, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[678/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[679/1000] \n",
      " TRAIN LOSS : 8.554091076056162, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[680/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[681/1000] \n",
      " TRAIN LOSS : 8.55409108930164, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[682/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[683/1000] \n",
      " TRAIN LOSS : 8.55409108930164, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[684/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[685/1000] \n",
      " TRAIN LOSS : 8.55409108930164, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[686/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[687/1000] \n",
      " TRAIN LOSS : 8.55409108930164, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[688/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[689/1000] \n",
      " TRAIN LOSS : 8.55409108930164, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[690/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[691/1000] \n",
      " TRAIN LOSS : 8.55409108930164, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[692/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[693/1000] \n",
      " TRAIN LOSS : 8.55409108930164, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[694/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[695/1000] \n",
      " TRAIN LOSS : 8.55409108930164, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[696/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[697/1000] \n",
      " TRAIN LOSS : 8.55409108930164, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[698/1000] \n",
      " TRAIN LOSS : 8.554090665446388, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[699/1000] \n",
      " TRAIN LOSS : 8.5540907714102, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[700/1000] \n",
      " TRAIN LOSS : 8.554090983337826, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[701/1000] \n",
      " TRAIN LOSS : 8.554090983337826, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[702/1000] \n",
      " TRAIN LOSS : 8.554090983337826, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[703/1000] \n",
      " TRAIN LOSS : 8.554090983337826, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[704/1000] \n",
      " TRAIN LOSS : 8.554090983337826, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[705/1000] \n",
      " TRAIN LOSS : 8.554090983337826, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[706/1000] \n",
      " TRAIN LOSS : 8.554090983337826, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[707/1000] \n",
      " TRAIN LOSS : 8.554090983337826, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[708/1000] \n",
      " TRAIN LOSS : 8.554090983337826, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[709/1000] \n",
      " TRAIN LOSS : 8.554090983337826, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[710/1000] \n",
      " TRAIN LOSS : 8.554090983337826, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[711/1000] \n",
      " TRAIN LOSS : 8.554090983337826, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[712/1000] \n",
      " TRAIN LOSS : 8.554090983337826, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[713/1000] \n",
      " TRAIN LOSS : 8.554090791278416, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[714/1000] \n",
      " TRAIN LOSS : 8.55409116215176, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[715/1000] \n",
      " TRAIN LOSS : 8.554090791278416, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[716/1000] \n",
      " TRAIN LOSS : 8.554091135660807, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[717/1000] \n",
      " TRAIN LOSS : 8.554090778032938, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[718/1000] \n",
      " TRAIN LOSS : 8.554091135660807, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[719/1000] \n",
      " TRAIN LOSS : 8.554090963469612, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[720/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[721/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[722/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[723/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[724/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[725/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[726/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[727/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[728/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[729/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[730/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[731/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[732/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[733/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[734/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[735/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[736/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[737/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[738/1000] \n",
      " TRAIN LOSS : 8.554091407193077, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[739/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[740/1000] \n",
      " TRAIN LOSS : 8.554090996583303, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[741/1000] \n",
      " TRAIN LOSS : 8.554090996583303, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[742/1000] \n",
      " TRAIN LOSS : 8.554090996583303, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[743/1000] \n",
      " TRAIN LOSS : 8.554090996583303, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[744/1000] \n",
      " TRAIN LOSS : 8.554090996583303, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[745/1000] \n",
      " TRAIN LOSS : 8.554091367456648, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[746/1000] \n",
      " TRAIN LOSS : 8.554090837637583, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[747/1000] \n",
      " TRAIN LOSS : 8.554090837637583, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[748/1000] \n",
      " TRAIN LOSS : 8.554090837637583, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[749/1000] \n",
      " TRAIN LOSS : 8.554090837637583, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[750/1000] \n",
      " TRAIN LOSS : 8.554090837637583, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[751/1000] \n",
      " TRAIN LOSS : 8.554090837637583, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[752/1000] \n",
      " TRAIN LOSS : 8.554090837637583, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[753/1000] \n",
      " TRAIN LOSS : 8.554090837637583, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[754/1000] \n",
      " TRAIN LOSS : 8.554090645578173, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[755/1000] \n",
      " TRAIN LOSS : 8.554090122381846, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[756/1000] \n",
      " TRAIN LOSS : 8.554091970125834, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[757/1000] \n",
      " TRAIN LOSS : 8.554090658823648, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[758/1000] \n",
      " TRAIN LOSS : 8.55409144030677, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[759/1000] \n",
      " TRAIN LOSS : 8.55409069193734, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[760/1000] \n",
      " TRAIN LOSS : 8.554090082645416, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[761/1000] \n",
      " TRAIN LOSS : 8.554090725051033, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[762/1000] \n",
      " TRAIN LOSS : 8.554090552859837, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[763/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[764/1000] \n",
      " TRAIN LOSS : 8.55409112241533, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[765/1000] \n",
      " TRAIN LOSS : 8.55409065220091, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[766/1000] \n",
      " TRAIN LOSS : 8.55409026145935, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[767/1000] \n",
      " TRAIN LOSS : 8.554090877374014, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[768/1000] \n",
      " TRAIN LOSS : 8.55409112241533, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[769/1000] \n",
      " TRAIN LOSS : 8.554090897242228, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[770/1000] \n",
      " TRAIN LOSS : 8.55409085088306, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[771/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[772/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[773/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[774/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[775/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[776/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[777/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[778/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[779/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[780/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[781/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[782/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[783/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[784/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[785/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[786/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[787/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[788/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[789/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[790/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[791/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[792/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[793/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[794/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[795/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[796/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[797/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[798/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[799/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[800/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[801/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[802/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[803/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[804/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[805/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[806/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[807/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[808/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[809/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[810/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[811/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[812/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[813/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[814/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[815/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[816/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[817/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[818/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[819/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[820/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[821/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[822/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[823/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[824/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[825/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[826/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[827/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[828/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[829/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[830/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[831/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[832/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[833/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[834/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[835/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[836/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[837/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[838/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[839/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[840/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[841/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[842/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[843/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[844/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[845/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[846/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[847/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[848/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[849/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[850/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[851/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[852/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[853/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[854/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[855/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[856/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[857/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[858/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[859/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[860/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[861/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[862/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[863/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[864/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[865/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[866/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[867/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[868/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[869/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[870/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[871/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[872/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[873/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[874/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[875/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[876/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[877/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[878/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[879/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[880/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[881/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[882/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[883/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[884/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[885/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[886/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[887/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[888/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[889/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[890/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[891/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[892/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[893/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[894/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[895/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[896/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[897/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[898/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[899/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[900/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[901/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[902/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[903/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[904/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[905/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[906/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[907/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[908/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[909/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[910/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[911/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[912/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[913/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[914/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[915/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[916/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[917/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[918/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[919/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[920/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[921/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[922/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[923/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[924/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[925/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[926/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[927/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[928/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[929/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[930/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[931/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[932/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[933/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[934/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[935/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[936/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[937/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[938/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[939/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[940/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[941/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[942/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[943/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[944/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[945/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[946/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[947/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[948/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[949/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[950/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[951/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[952/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[953/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[954/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[955/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[956/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[957/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[958/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[959/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[960/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[961/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[962/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[963/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[964/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[965/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[966/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[967/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[968/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[969/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[970/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[971/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[972/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[973/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[974/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[975/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[976/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[977/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[978/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[979/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[980/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[981/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[982/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[983/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[984/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[985/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[986/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[987/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[988/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[989/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[990/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[991/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[992/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[993/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[994/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[995/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[996/1000] \n",
      " TRAIN LOSS : 8.554091175397238, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n",
      "[997/1000] \n",
      " TRAIN LOSS : 8.55409061908722, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925016641616821, F1 : 0.2916666567325592\n",
      "[998/1000] \n",
      " TRAIN LOSS : 8.554091235001883, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.1925015449523926, F1 : 0.2916666567325592\n",
      "[999/1000] \n",
      " TRAIN LOSS : 8.554091016451517, F1 : 0.037037038140826754\n",
      "VAL LOSS : 1.192501425743103, F1 : 0.2916666567325592\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 진행\n",
    "loss, F1 = training(model, featureDF, targetDF, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 후 loss 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "THRESHOLD=100\n",
    "fg, axes=plt.subplots(1,2,figsize=(10,5))\n",
    "axes[0].plot(range(1, THRESHOLD+1), loss[0][:THRESHOLD], label='Train')\n",
    "axes[0].plot(range(1, THRESHOLD+1), loss[1][:THRESHOLD], label='Val')\n",
    "axes[0].grid()\n",
    "axes[0].legend()\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Epoch&Loss')\n",
    "\n",
    "axes[1].plot(range(1, THRESHOLD+1), F1[0][:THRESHOLD], label='Train')\n",
    "axes[1].plot(range(1, THRESHOLD+1), F1[1][:THRESHOLD], label='Val')\n",
    "axes[1].grid()\n",
    "axes[1].legend()\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Epoch&Loss')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
