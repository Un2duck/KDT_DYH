{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DNN 기반 회귀 모델 구현\n",
    "- 데이터셋   : iris.csv\n",
    "- 피쳐/속성  : 4개 Sepal_Length, Sepal_width, Petal_Length, Petal_width\n",
    "- 타겟/라벨  : 1개 Setosa와 나머지\n",
    "- 학습/방법  : 지도학습 -> 회귀\n",
    "- 알고리즘   : 인공신경망(ANN) -> MLP, DNN : 은닉층이 많은 구성\n",
    "- 프레임워크 : Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 관련 모듈 로딩\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.nn.functional as F  \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchmetrics.classification import F1Score, BinaryF1Score\n",
    "from torchmetrics.classification import BinaryConfusionMatrix\n",
    "from torchinfo import summary\n",
    "\n",
    "# 데이터 관련 모듈 로딩\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch V.:2.4.1\n",
      "pandas V.:2.0.3\n"
     ]
    }
   ],
   "source": [
    "# 활용 패키지 버전 체크\n",
    "print(f'torch V.:{torch.__version__}')\n",
    "print(f'pandas V.:{pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 데이터 로딩\n",
    "DATA_FILE='../Data/iris.csv'\n",
    "\n",
    "### CSV => DataFrame\n",
    "irisDF = pd.read_csv(DATA_FILE)\n",
    "\n",
    "### 확인\n",
    "irisDF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Setosa', 'Versicolor', 'Virginica'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 타겟 변경 => 정수화, 클래스 3개 => 2개\n",
    "irisDF['variety'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisDF['variety'] = (irisDF['variety'] == 'Setosa')\n",
    "irisDF['variety']=irisDF['variety'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels=dict(zip(irisDF['variety'].unique().tolist(),range(3)))\n",
    "# print(f'labels => {labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 모델 클래스 설계 및 정의 <hr>\n",
    "- 클래스목적 : iris 데이터를 학습 및 추론\n",
    "- 클래스이름 : irisBCFModel\n",
    "- 부모클래스 : nn.Module\n",
    "- 매개 변수 : 층별 입출력 개수 고정하기 때문에 필요 x!\n",
    "- 속성 필드 : \n",
    "- 기능 역할 : __ init__() : 모델 구조 설정, forward() : 순방향 학습 <= 오버라이딩(overriding) - [상속 시 가능!]\n",
    "- 클래스구조\n",
    "    * 입력층 : 입력 4개(피쳐)  출력 10개 (퍼셉트론/뉴런 10개 존재)\n",
    "    * 은닉층 : 입력 10개       출력 5개 (퍼셉트론/뉴런 30개 존재)\n",
    "    * 출력층 : 입력 5개        출력 1개 (퍼셉트론/뉴런 1개 존재 : 2진분류)\n",
    "\n",
    "- 활성화함수\n",
    "    * 클래스 형태 ==> ex) nn.MESLoss, nn.ReLU ==> __ init__(self) 메서드\n",
    "    * 함수 형태 ==> torch.nn.functional 아래에 ==> forward(self) 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class irisBCFModel(nn.Module):\n",
    "\n",
    "    # 모델 구조 구성 및 인스턴스 생성 메서드\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_layer=nn.Linear(4, 10)\n",
    "        self.hidden_layer=nn.Linear(10, 5)\n",
    "        self.out_layer=nn.Linear(5, 1)\n",
    "\n",
    "    # 순방향 학습 진행 메서드\n",
    "    def forward(self, x):\n",
    "        # - 입력층\n",
    "        y = self.in_layer(x)     # y = f1w1 + f2w2 + f3w3 + b ... -> 10개\n",
    "        y = F.relu(y)            # relu -> y 값의 범위 0 <= y\n",
    "        \n",
    "        # - 은닉층 : 5개의 숫자 값(>=0)\n",
    "        y = self.hidden_layer(y) # y = f21w21 + ... + f210w210 , ... -> 5개\n",
    "        y = F.relu(y)            # relu -> y 값의 범위 0 <= y\n",
    "\n",
    "        # - 출력층 : 1개의 숫자 값(>=0)\n",
    "        return F.sigmoid(self.out_layer(y))        # f31w31 + ... f330w330 + b -> 1개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irisBCFModel(\n",
      "  (in_layer): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (hidden_layer): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (out_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## 모델 인스턴스 생성\n",
    "model = irisBCFModel()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "irisBCFModel                             [17, 1]                   --\n",
       "├─Linear: 1-1                            [17, 10]                  50\n",
       "├─Linear: 1-2                            [17, 5]                   55\n",
       "├─Linear: 1-3                            [17, 1]                   6\n",
       "==========================================================================================\n",
       "Total params: 111\n",
       "Trainable params: 111\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 사용 메모리 정보 확인\n",
    "summary(model, input_size=(17,4)) # input_size = ,feature 개수)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 데이터셋 클래스 설계 및 정의 <hr>\n",
    "- 데이터셋 : iris.csv\n",
    "- 피쳐_개수 : 3개\n",
    "- 타겟_개수 : 1개\n",
    "- 클래스이름 : IrisDataset\n",
    "- 부모클래스 : utils.data.Dataset\n",
    "- 속성_필드 : featureDF, targetDF, n_rows, n_features\n",
    "- 필수메서드 : \n",
    "    * __ init__(self): 데이터셋 저장 및 전처리, 개발자가 필요한 속성 설정\n",
    "    * __ len__(self): 데이터의 개수 반환\n",
    "    * __ getitem__(self, index): 특정 인덱스의 피쳐와 타겟 반환\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(Dataset):\n",
    "\n",
    "    def __init__(self, featureDF, targetDF):\n",
    "        self.featureDF=featureDF\n",
    "        self.targetDF=targetDF\n",
    "        self.n_rows=featureDF.shape[0]\n",
    "        self.n_features=featureDF.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 텐서화\n",
    "        featureTS=torch.FloatTensor(self.featureDF.iloc[index].values)\n",
    "        targetTS=torch.FloatTensor(self.targetDF.iloc[index].values)\n",
    "        \n",
    "        # 피쳐와 타겟 반환\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4]) torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "## [테스트] 데이터셋 인스턴스 생성\n",
    "\n",
    "# DataFrame에서 피쳐와 타겟 추출\n",
    "featureDF = irisDF[irisDF.columns[:-1]]     # 2D (150, 3)\n",
    "targetDF = irisDF[irisDF.columns[-1:]]      # 2D (150, 1)\n",
    "\n",
    "# - 커스텀데이터셋 인스턴스 생성\n",
    "irisDS=IrisDataset(featureDF, targetDF)\n",
    "\n",
    "# - 데이터로더 인스턴스 생성\n",
    "irisDL=DataLoader(irisDS)\n",
    "\n",
    "for feature, label in irisDL:\n",
    "    print(feature.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 학습 준비 <hr>\n",
    "- 학습 횟수 : EPOCH          <- 처음~ 끝까지 공부하는 단위\n",
    "- 배치 크기 : BATCH_SIZE     <- 한번에 학습할 데이터셋 양\n",
    "- 위치 지정 : DEVICE         <- 탠서 저장 및 실행 위치 (GPU/CPU)\n",
    "- 학 습 률 : LR 가중치와 절편 업데이트 시 경사하강법으로 업데이트 간격 설정 0.001 ~ 0.1 (낮을수록 촘촘히)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_CNT: 15\n"
     ]
    }
   ],
   "source": [
    "### 학습 진행 관련 설정\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 10\n",
    "BATCH_CNT = irisDF.shape[0]//BATCH_SIZE\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR = 0.001\n",
    "\n",
    "print(f'BATCH_CNT: {BATCH_CNT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인스턴스/객체 : 모델, 데이터셋, 최적화, (손실함수), (성능지표)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X_train(shape): (84, 4) (type): <class 'pandas.core.frame.DataFrame'>], X_test: (38, 4), X_val: (28, 4)\n",
      "[y_train(shape): (84, 1) (type): <class 'pandas.core.frame.DataFrame'>], y_test: (38, 1), y_val: (28, 1)\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스\n",
    "model=irisBCFModel()\n",
    "\n",
    "# 데이터셋 인스턴스\n",
    "# 학습용, 검증용, 테스트용 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(featureDF, targetDF, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=1)\n",
    "print(f'[X_train(shape): {X_train.shape} (type): {type(X_train)}], X_test: {X_test.shape}, X_val: {X_val.shape}')\n",
    "print(f'[y_train(shape): {y_train.shape} (type): {type(y_train)}], y_test: {y_test.shape}, y_val: {y_val.shape}')\n",
    "\n",
    "trainDS=IrisDataset(X_train, y_train)\n",
    "valDS=IrisDataset(X_val, y_val)\n",
    "testDS=IrisDataset(X_test, y_test)\n",
    "\n",
    "# - 학습용 데이터로더 인스턴스\n",
    "trainDL=DataLoader(trainDS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최적화, 손실함수 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 인스턴스 => W,b 텐서 즉, model.parameters() 전달\n",
    "optimizer=optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# 손실함수 인스턴스 => 분류 => 이진분류 BinaryCrossEntropyLoss => BCELoss\n",
    "#                            예측값은 확률값으로 전달 ==> sigmoid() AF 처리 후 전달\n",
    "bce_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function math.ceil(x, /)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math as m    \n",
    "m.ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDS.n_rows, trainDS.featureDF.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 학습 진행 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new BATCH_CNT : 9\n",
      "1/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "2/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "3/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "4/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "5/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "6/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "7/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "8/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "9/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "10/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "11/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "12/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "13/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "14/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "15/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "16/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "17/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "18/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "19/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "20/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "21/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "22/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "23/1000 => [TRAIN] LOSS: 0.005454874873161316 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "24/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "25/1000 => [TRAIN] LOSS: 0.005454874813556671 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "26/1000 => [TRAIN] LOSS: 0.005454874694347382 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "27/1000 => [TRAIN] LOSS: 0.005454874694347382 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "28/1000 => [TRAIN] LOSS: 0.005454874694347382 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "29/1000 => [TRAIN] LOSS: 0.005454874694347382 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "30/1000 => [TRAIN] LOSS: 0.005454874694347382 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "31/1000 => [TRAIN] LOSS: 0.005454874694347382 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "32/1000 => [TRAIN] LOSS: 0.005454874694347382 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "33/1000 => [TRAIN] LOSS: 0.005454874694347382 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "34/1000 => [TRAIN] LOSS: 0.005454874694347382 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "35/1000 => [TRAIN] LOSS: 0.005454874694347382 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "36/1000 => [TRAIN] LOSS: 0.005454874694347382 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "37/1000 => [TRAIN] LOSS: 0.005454874694347382 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "38/1000 => [TRAIN] LOSS: 0.005454874694347382 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "39/1000 => [TRAIN] LOSS: 0.005454874694347382 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "40/1000 => [TRAIN] LOSS: 0.005454874694347382 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232764959335327 SCORE: 0.0\n",
      "41/1000 => [TRAIN] LOSS: 0.005454874575138092 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "42/1000 => [TRAIN] LOSS: 0.005454874604940415 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "43/1000 => [TRAIN] LOSS: 0.005454874604940415 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "44/1000 => [TRAIN] LOSS: 0.005454874843358994 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "45/1000 => [TRAIN] LOSS: 0.005454874843358994 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "46/1000 => [TRAIN] LOSS: 0.005454874843358994 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "47/1000 => [TRAIN] LOSS: 0.005454874902963638 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "48/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "49/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "50/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "51/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "52/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "53/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "54/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "55/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "56/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "57/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "58/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "59/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "60/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "61/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "62/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "63/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "64/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "65/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "66/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "67/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "68/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "69/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "70/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "71/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "72/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "73/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "74/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "75/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "76/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "77/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "78/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "79/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "80/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "81/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "82/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "83/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "84/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "85/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "86/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "87/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "88/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "89/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "90/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "91/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "92/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "93/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "94/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "95/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "96/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "97/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "98/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "99/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "100/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "101/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "102/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "103/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "104/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "105/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "106/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "107/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "108/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "109/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "110/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "111/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "112/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "113/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "114/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "115/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "116/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "117/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "118/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "119/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "120/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "121/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "122/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "123/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "124/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "125/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "126/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "127/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "128/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "129/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "130/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "131/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "132/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "133/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "134/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "135/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "136/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "137/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "138/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "139/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "140/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "141/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "142/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "143/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "144/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "145/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "146/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "147/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "148/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "149/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "150/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "151/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "152/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "153/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "154/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "155/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "156/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "157/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "158/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "159/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "160/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "161/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "162/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "163/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "164/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "165/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "166/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "167/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "168/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "169/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "170/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "171/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "172/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "173/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "174/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "175/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "176/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "177/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "178/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "179/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "180/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "181/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "182/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "183/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "184/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "185/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "186/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "187/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "188/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "189/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "190/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "191/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "192/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "193/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "194/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "195/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "196/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "197/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "198/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "199/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "200/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "201/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "202/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "203/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "204/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "205/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "206/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "207/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "208/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "209/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "210/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "211/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "212/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "213/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "214/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "215/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "216/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "217/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "218/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "219/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "220/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "221/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "222/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "223/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "224/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "225/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "226/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "227/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "228/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "229/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "230/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "231/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "232/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "233/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "234/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "235/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "236/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "237/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "238/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "239/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "240/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "241/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "242/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "243/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "244/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "245/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "246/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "247/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "248/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "249/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "250/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "251/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "252/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "253/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "254/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "255/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "256/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "257/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "258/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "259/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "260/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "261/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "262/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "263/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "264/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "265/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "266/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "267/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "268/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "269/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "270/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "271/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "272/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "273/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "274/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "275/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "276/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "277/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "278/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "279/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "280/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "281/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "282/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "283/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "284/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "285/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "286/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "287/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "288/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "289/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "290/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "291/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "292/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "293/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "294/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "295/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "296/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "297/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "298/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "299/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "300/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "301/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "302/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "303/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "304/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "305/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "306/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "307/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "308/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "309/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "310/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "311/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "312/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "313/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "314/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "315/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "316/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "317/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "318/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "319/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "320/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "321/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "322/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "323/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "324/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "325/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "326/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "327/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "328/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "329/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "330/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "331/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "332/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "333/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "334/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "335/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "336/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "337/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "338/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "339/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "340/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "341/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "342/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "343/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "344/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "345/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "346/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "347/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "348/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "349/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "350/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "351/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "352/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "353/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "354/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "355/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "356/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "357/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "358/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "359/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "360/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "361/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "362/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "363/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "364/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "365/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "366/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "367/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "368/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "369/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "370/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "371/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "372/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "373/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "374/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "375/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "376/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "377/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "378/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "379/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "380/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "381/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "382/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "383/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "384/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "385/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "386/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "387/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "388/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "389/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "390/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "391/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "392/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "393/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "394/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "395/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "396/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "397/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "398/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "399/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "400/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "401/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "402/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "403/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "404/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "405/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "406/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "407/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "408/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "409/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "410/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "411/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "412/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "413/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "414/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "415/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "416/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "417/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "418/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "419/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "420/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "421/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "422/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "423/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "424/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "425/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "426/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "427/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "428/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "429/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "430/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "431/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "432/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "433/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "434/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "435/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "436/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "437/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "438/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "439/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "440/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "441/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "442/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "443/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "444/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "445/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "446/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "447/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "448/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "449/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "450/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "451/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "452/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "453/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "454/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "455/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "456/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "457/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "458/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "459/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "460/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "461/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "462/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "463/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "464/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "465/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "466/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "467/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "468/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "469/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "470/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "471/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "472/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "473/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "474/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "475/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "476/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "477/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "478/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "479/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "480/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "481/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "482/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "483/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "484/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "485/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "486/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "487/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "488/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "489/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "490/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "491/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "492/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "493/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "494/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "495/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "496/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "497/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "498/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "499/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "500/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "501/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "502/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "503/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "504/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "505/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "506/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "507/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "508/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "509/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "510/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "511/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "512/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "513/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "514/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "515/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "516/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "517/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "518/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "519/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "520/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "521/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "522/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "523/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "524/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "525/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "526/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "527/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "528/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "529/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "530/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "531/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "532/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "533/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "534/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "535/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "536/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "537/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "538/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "539/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "540/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "541/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "542/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "543/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "544/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "545/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "546/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "547/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "548/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "549/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "550/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "551/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "552/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "553/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "554/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "555/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "556/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "557/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "558/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "559/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "560/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "561/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "562/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "563/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "564/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "565/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "566/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "567/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "568/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "569/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "570/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "571/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "572/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "573/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "574/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "575/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "576/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "577/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "578/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "579/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "580/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "581/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "582/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "583/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "584/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "585/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "586/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "587/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "588/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "589/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "590/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "591/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "592/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "593/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "594/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "595/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "596/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "597/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "598/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "599/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "600/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "601/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "602/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "603/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "604/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "605/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "606/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "607/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "608/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "609/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "610/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "611/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "612/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "613/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "614/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "615/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "616/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "617/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "618/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "619/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "620/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "621/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "622/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "623/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "624/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "625/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "626/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "627/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "628/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "629/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "630/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "631/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "632/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "633/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "634/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "635/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "636/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "637/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "638/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "639/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "640/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "641/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "642/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "643/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "644/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "645/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "646/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "647/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "648/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "649/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "650/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "651/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "652/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "653/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "654/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "655/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "656/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "657/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "658/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "659/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "660/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "661/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "662/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "663/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "664/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "665/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "666/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "667/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "668/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "669/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "670/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "671/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "672/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "673/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "674/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "675/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "676/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "677/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "678/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "679/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "680/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "681/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "682/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "683/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "684/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "685/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "686/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "687/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "688/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "689/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "690/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "691/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "692/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "693/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "694/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "695/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "696/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "697/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "698/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "699/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "700/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "701/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "702/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "703/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "704/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "705/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "706/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "707/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "708/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "709/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "710/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "711/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "712/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "713/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "714/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "715/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "716/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "717/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "718/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "719/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "720/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "721/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "722/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "723/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "724/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "725/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "726/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "727/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "728/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "729/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "730/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "731/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "732/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "733/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "734/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "735/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "736/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "737/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "738/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "739/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "740/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "741/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "742/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "743/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "744/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "745/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "746/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "747/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "748/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "749/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "750/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "751/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "752/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "753/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "754/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "755/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "756/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "757/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "758/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "759/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "760/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "761/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "762/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "763/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "764/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "765/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "766/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "767/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "768/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "769/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "770/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "771/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "772/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "773/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "774/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "775/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "776/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "777/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "778/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "779/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "780/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "781/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "782/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "783/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "784/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "785/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "786/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "787/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "788/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "789/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "790/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "791/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "792/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "793/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "794/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "795/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "796/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "797/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "798/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "799/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "800/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "801/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "802/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "803/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "804/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "805/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "806/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "807/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "808/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "809/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "810/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "811/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "812/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "813/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "814/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "815/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "816/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "817/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "818/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "819/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "820/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "821/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "822/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "823/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "824/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "825/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "826/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "827/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "828/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "829/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "830/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "831/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "832/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "833/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "834/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "835/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "836/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "837/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "838/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "839/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "840/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "841/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "842/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "843/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "844/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "845/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "846/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "847/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "848/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "849/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "850/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "851/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "852/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "853/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "854/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "855/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "856/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "857/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "858/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "859/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "860/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "861/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "862/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "863/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "864/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "865/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "866/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "867/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "868/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "869/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "870/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "871/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "872/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "873/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "874/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "875/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "876/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "877/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "878/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "879/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "880/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "881/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "882/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "883/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "884/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "885/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "886/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "887/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "888/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "889/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "890/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "891/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "892/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "893/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "894/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "895/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "896/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "897/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "898/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "899/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "900/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "901/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "902/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "903/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "904/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "905/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "906/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "907/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "908/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "909/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "910/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "911/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "912/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "913/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "914/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "915/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "916/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "917/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "918/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "919/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "920/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "921/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "922/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "923/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "924/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "925/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "926/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "927/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "928/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "929/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "930/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "931/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "932/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "933/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "934/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "935/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "936/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "937/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "938/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "939/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "940/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "941/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "942/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "943/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "944/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "945/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "946/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "947/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "948/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "949/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "950/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "951/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "952/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "953/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "954/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "955/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "956/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "957/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "958/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "959/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "960/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "961/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "962/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "963/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "964/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "965/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "966/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "967/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "968/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "969/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "970/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "971/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "972/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "973/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "974/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "975/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "976/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "977/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "978/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "979/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "980/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "981/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "982/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "983/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "984/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "985/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "986/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "987/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "988/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "989/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "990/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "991/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "992/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "993/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "994/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "995/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "996/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "997/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "998/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n",
      "999/1000 => [TRAIN] LOSS: 0.005454874962568283 SCORE: 0.0\n",
      "[VAL] LOSS: 0.7232766151428223 SCORE: 0.0\n"
     ]
    }
   ],
   "source": [
    "## 학습의 효과 확인 => 손실값과 성능평가값 저장 필요\n",
    "loss_history, score_history=[[],[]], [[],[]] # train, val\n",
    "CNT=len(trainDL)\n",
    "print(f'new BATCH_CNT : {CNT}')\n",
    "# 학습 모드로 모델 설정\n",
    "model.train()\n",
    "\n",
    "for epoch in range(1, EPOCHS):\n",
    "    # 학습 모드로 모델 설정\n",
    "    model.train()\n",
    "\n",
    "    # 배치 크기 만큼 데이터 로딩해서 학습 진행\n",
    "    loss_total, score_total=0,0\n",
    "    for featureTS, targetTS in trainDL:\n",
    "\n",
    "        # 학습 진행\n",
    "        pre_y=model(featureTS)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss=bce_loss(pre_y, targetTS)\n",
    "        loss_total+=loss.item()\n",
    "        \n",
    "        # 성능평가 계산\n",
    "        # score=F1Score(task='binary')(pre_y, targetTS)\n",
    "        score=BinaryF1Score()(pre_y, targetTS)\n",
    "        score_total+=score.item()\n",
    "\n",
    "        # 최적화 진행\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 검증 모드로 모델 설정\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 검증 데이터셋\n",
    "        val_featureTS=torch.FloatTensor(valDS.featureDF.values)\n",
    "        val_targetTS=torch.FloatTensor(valDS.targetDF.values)\n",
    "        \n",
    "        # 평가\n",
    "        pre_val=model(val_featureTS)\n",
    "\n",
    "        # 손실\n",
    "        loss_val=bce_loss(pre_val, val_targetTS)\n",
    "\n",
    "        # 성능평가\n",
    "        # score_val=F1Score(task='binary')(pre_val, val_targetTS)\n",
    "        score_val=BinaryF1Score()(pre_val, val_targetTS)\n",
    "\n",
    "    # 에포크당 손실값과 성능평가값 저장\n",
    "    loss_history[0].append(loss_total/epoch)\n",
    "    score_history[0].append(score_total/epoch)\n",
    "\n",
    "    loss_history[1].append(loss_val)\n",
    "    score_history[1].append(score_val)\n",
    "\n",
    "    print(f'{epoch}/{EPOCHS} => [TRAIN] LOSS: {loss_history[0][-1]} SCORE: {score_history[0][-1]}')\n",
    "    print(f'[VAL] LOSS: {loss_history[1][-1]} SCORE: {score_history[1][-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[테스트 & 검증 상태]\n",
    "- 설정된 W,b 검증 및 테스트용 데이터셋 예측값 추출\n",
    "- 사용되지 않는 기능들 OFF\n",
    "- W, b 업데이트 X\n",
    "    * -> 기능 OFF Auto_grade 엔진 ---> model.eval()\n",
    "    * -> W, b 텐서 required_grade=True ---> no.grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6] 학습결과 시각화\n",
    "- 학습과 검증의 Loss 변화, 성능 변화 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 후 loss 시각화\n",
    "\n",
    "THRESHOLD=10\n",
    "fg, axes=plt.subplots(1,2,figsize=(10,5))\n",
    "axes[0].plot(range(1, THRESHOLD+1), loss_history[0][:THRESHOLD], label='Train')\n",
    "axes[0].plot(range(1, THRESHOLD+1), loss_history[1][:THRESHOLD], label='Val')\n",
    "axes[0].grid()\n",
    "axes[0].legend()\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Epoch&Loss')\n",
    "\n",
    "axes[1].plot(range(1, THRESHOLD+1), score_history[0][:THRESHOLD], label='Train')\n",
    "axes[1].plot(range(1, THRESHOLD+1), score_history[1][:THRESHOLD], label='Val')\n",
    "axes[1].grid()\n",
    "axes[1].legend()\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('Epoch&Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
