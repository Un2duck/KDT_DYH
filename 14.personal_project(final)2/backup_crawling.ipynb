{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import Request\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from urllib.parse import urlparse\n",
    "from selenium_stealth import stealth # 셀레니움 스텔스 기능\n",
    "\n",
    "# 예외 처리\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 지정 함수 부분 \n",
    "\n",
    "# smartDF 만드는 함수\n",
    "def makeLinkDF(storelink, storename):\n",
    "    smartDF = pd.DataFrame([storelink, storename])\n",
    "    smartDF.index=['링크','상점']\n",
    "    smartDF = smartDF.T\n",
    "    return smartDF\n",
    "\n",
    "# 기존 파일영역(saveDF)에 추가(newDF)해줌.\n",
    "def concatFile(saveDF, newDF): \n",
    "    saveDF=pd.read_excel('./Data/output.xlsx')\n",
    "    saveDF.drop(['Unnamed: 0'], axis=1, inplace=True) # 불러오면 'Unnamed: 0' 제거해줘야함.\n",
    "    updateDF=pd.concat([saveDF, newDF])\n",
    "    return updateDF\n",
    "\n",
    "# 스크롤을 내리는 함수 (페이지 끝까지)\n",
    "def scroll_to_end(driver):\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2) # 페이지가 로드되는 동안 대기\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "# 링크 DF 만드는 함수 (상품, 해당 링크)\n",
    "def makeLinks(name_list, link_list):\n",
    "    dataDF = pd.DataFrame([name_list, link_list])\n",
    "    dataDF.index=['상품','링크']\n",
    "    dataDF = dataDF.T\n",
    "    return dataDF\n",
    "\n",
    "# smartDF 파일 업데이트하기\n",
    "def updateLink(smartDF, filename):\n",
    "    baseDF=pd.read_excel(filename)\n",
    "    smartDF=pd.concat([baseDF, smartDF])\n",
    "    smartDF.drop(['Unnamed: 0'], axis=1, inplace=True) # 'Unnamed: 0' 제거해줘야함.\n",
    "    smartDF.to_excel(filename)\n",
    "    return smartDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 초기 방법 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_option = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(options=agent_option)\n",
    "\n",
    "user_agent_string = 'Mozilla/5.0'\n",
    "agent_option.add_argument('user-agent=' + user_agent_string)\n",
    "\n",
    "original_window = driver.current_window_handle\n",
    "\n",
    "### 사이트 진입\n",
    "url = 'https://search.shopping.naver.com/catalog/38387900618?&NaPm=ct%3Dm3o6cnzk%7Cci%3Dd6e42fe5a7117073bf0cf10be64e41caf8e0dd9b%7Ctr%3Dslcc%7Csn%3D95694%7Chk%3D57ed9b59c78d943e9049a790240b2c9b7e878a35'\n",
    "driver.get(url)\n",
    "\n",
    "# 링크 클릭\n",
    "link = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//*[@id=\"section_price\"]/div[4]/ul/li[1]/div/div[2]/a'))\n",
    ")\n",
    "link.click()\n",
    "\n",
    "# 새 탭으로 전환\n",
    "new_window = [window for window in driver.window_handles if window != original_window][0]\n",
    "driver.switch_to.window(new_window)\n",
    "\n",
    "# 새 탭의 URL 가져오기\n",
    "current_url = driver.current_url\n",
    "\n",
    "# 도메인 추출\n",
    "parsed_url = urlparse(current_url)\n",
    "domain = parsed_url.netloc\n",
    "\n",
    "base_url = f\"{parsed_url.scheme}://{parsed_url.netloc}\" \n",
    "\n",
    "print(f\"새 탭에서 열린 URL: {current_url}\") # 'https://smartstore.naver.com/fullylight/products/...\n",
    "print(f\"도메인 주소: {domain}\") # ex) smartstore.naver.com\n",
    "print(f\"base_url: {base_url}\") # ex) https://smartstore.naver.com\n",
    "\n",
    "# 새 탭 닫기 및 원래 탭으로 복귀\n",
    "driver.close()\n",
    "driver.switch_to.window(original_window)\n",
    "\n",
    "# links = driver.find_elements(By.CLASS_NAME, \"productList_title__R1qZP\")\n",
    "# for idx, link in enumerate(links):\n",
    "#     link.click()\n",
    "\n",
    "# time.sleep(3)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가격비교 1개에서 링크 가져오기 샘플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_option = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(options=agent_option)\n",
    "\n",
    "user_agent_string = 'Mozilla/5.0'\n",
    "agent_option.add_argument('user-agent=' + user_agent_string)\n",
    "\n",
    "original_window = driver.current_window_handle\n",
    "\n",
    "### 사이트 진입\n",
    "url = 'https://search.shopping.naver.com/catalog/45311333618?&NaPm=ct%3Dm3ogn9t4%7Cci%3Db9b07e10143aa65bb1fa8a4472d058f5541ff320%7Ctr%3Dslcc%7Csn%3D95694%7Chk%3D5a4815a72a9899c0f573073d053040e78a77dbe9'\n",
    "driver.get(url)\n",
    "\n",
    "# URL 가져오기\n",
    "current_url = driver.current_url\n",
    "\n",
    "# 도메인 추출\n",
    "parsed_url = urlparse(current_url)\n",
    "path_seg = parsed_url.path.split('/')\n",
    "# 링크 생성\n",
    "smartstore = []\n",
    "\n",
    "for i in range(2, 12):\n",
    "    link = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable(\n",
    "            (By.XPATH, f'//*[@id=\"section_price\"]/div[4]/ul/li[{i}]/div/div[1]')))\n",
    "    link.click()\n",
    "    text = link.text\n",
    "    time.sleep(2)\n",
    "\n",
    "    # 새 탭으로 전환\n",
    "    new_window = [window for window in driver.window_handles if window != original_window][0]\n",
    "    driver.switch_to.window(new_window)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # 새 탭의 URL 가져오기\n",
    "    current_url = driver.current_url\n",
    "\n",
    "    # 도메인 추출\n",
    "    parsed_url = urlparse(current_url)\n",
    "    domain = parsed_url.netloc\n",
    "    base_url = f\"{parsed_url.scheme}://{parsed_url.netloc}\" \n",
    "\n",
    "    # 스마트스토어 리스트 추출\n",
    "    if base_url == 'https://smartstore.naver.com':\n",
    "        path_seg = parsed_url.path.split('/')\n",
    "        smart_id = path_seg[1]\n",
    "        qna = base_url + '/' + path_seg[1] + '/qna'\n",
    "        if qna not in smartstore:\n",
    "            smartstore.append(qna)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    print(f\"도메인 주소: {domain}\") # ex) smartstore.naver.com\n",
    "    print(f\"base_url: {base_url}\") # ex) https://smartstore.naver.com\n",
    "    print(f\"smart_id: {smart_id}\") # ex) isround\n",
    "    print(f\"text: {text}\")\n",
    "\n",
    "    # 새 탭 닫기 및 원래 탭으로 복귀\n",
    "    driver.close()\n",
    "    driver.switch_to.window(original_window)\n",
    "    time.sleep(2)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 상품들 링크 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "agent_option = webdriver.ChromeOptions()\n",
    "\n",
    "user_agent_string = 'Mozilla/5.0'\n",
    "agent_option.add_argument('user-agent=' + user_agent_string)\n",
    "\n",
    "url = \"https://search.shopping.naver.com/search/category/100007873?adQuery&catId=50000024&origQuery&pagingIndex=1&pagingSize=80&productSet=total&query&sort=review_rel&timestamp=&viewType=list\"\n",
    "driver.get(url)\n",
    "\n",
    "for i in range(1,11):\n",
    "\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "    # 스크롤을 최대한 밑으로 내림 (동적 Javascript)\n",
    "    scroll_to_end(driver)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    driver.find_element(By.CLASS_NAME, 'pagination_next__pZuC6').click() # 다음 클릭하기\n",
    "    time.sleep(10)\n",
    "\n",
    "    # 스크롤을 최대한 밑으로 내림 (동적 Javascript)\n",
    "    scroll_to_end(driver)\n",
    "    time.sleep(5)\n",
    "\n",
    "    # 페이지 소스 soup로 가져오기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    time.sleep(1)\n",
    "\n",
    "    ### 링크 가져오기\n",
    "    \n",
    "    link_tags = soup.select('div.product_title__Mmw2K > a')\n",
    "\n",
    "    ### 링크 리스트\n",
    "    link_list=[]\n",
    "    name_list=[]\n",
    "    for tag in link_tags:\n",
    "\n",
    "        name_tag = tag.text.strip() # 이름 가져오기\n",
    "        name_list.append(name_tag)\n",
    "\n",
    "        link_tag = tag['href'] # 링크 가져오기\n",
    "        link_list.append(link_tag)\n",
    "\n",
    "    print(name_list)\n",
    "    print(link_list)\n",
    "\n",
    "    linkDF = makeLinks(name_list, link_list)\n",
    "    linkDF = updateLink(linkDF)\n",
    "    print(f'link 누적개수 : {len(linkDF)}')\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- smartlinks 사이트 형태 파악하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storelinks = pd.read_excel('smartlinks.xlsx')\n",
    "agent_option = webdriver.ChromeOptions()\n",
    "checklist = []\n",
    "for idx, storelink in enumerate(storelinks['링크']):\n",
    "    ### 사이트 진입\n",
    "    user_agent_string = 'Mozilla/5.0'\n",
    "    agent_option.add_argument('user-agent=' + user_agent_string)\n",
    "    driver = webdriver.Chrome(options=agent_option)\n",
    "    stealth(driver,\n",
    "            languages=[\"en-US\", \"en\"],\n",
    "            vendor=\"Google Inc.\",\n",
    "            platform=\"Win32\",\n",
    "            webgl_vendor=\"Intel Inc.\",\n",
    "            renderer=\"Intel Iris OpenGL Engine\",\n",
    "            fix_hairline=True,\n",
    "            )\n",
    "    driver.get(storelink)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # URL 가져오기\n",
    "    current_url = driver.current_url\n",
    "    main_parsed_url = urlparse(current_url)\n",
    "    time.sleep(1)\n",
    "    main_path_seg = main_parsed_url.path.split('/')\n",
    "    print(f\"main_parsed_url: {main_parsed_url}\")\n",
    "    print(f\"main_path_seg[1]: {main_path_seg[1]}\")\n",
    "    if main_path_seg[1] == 'catalog':\n",
    "        checklist.append('카탈로그')\n",
    "    else:\n",
    "        checklist.append('그 외')\n",
    "    driver.quit()\n",
    "\n",
    "# 카탈로그 라벨링한 파일 내보내기\n",
    "storelinks['상점'] = checklist\n",
    "storelinks.to_excel('storelinks.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 변수 지정\n",
    "file = './rawfile.xlsx'\n",
    "\n",
    "# 카탈로그 파일 가져오기\n",
    "catalog_links = pd.read_excel('storelinks(catalog).xlsx')\n",
    "\n",
    "### 사이트 진입\n",
    "for catalog in catalog_links['링크']:\n",
    "    agent_option = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(options=agent_option)\n",
    "\n",
    "    user_agent_string = 'Mozilla/5.0'\n",
    "    agent_option.add_argument('user-agent=' + user_agent_string)\n",
    "\n",
    "    original_window = driver.current_window_handle\n",
    "    driver.get(catalog)\n",
    "\n",
    "    product_list = driver.find_elements(By.CLASS_NAME, 'productList_title__R1qZP')\n",
    "    \n",
    "    # 링크 생성 또는 링크 로딩\n",
    "    if not os.path.exists(file):\n",
    "        storelink, storename = [], []\n",
    "    else:\n",
    "        fileDF = pd.read_excel(file)\n",
    "        storelink = fileDF['링크'].to_list()\n",
    "        storename = fileDF['상점'].to_list()\n",
    "\n",
    "    for i in range(1, len(product_list)+1):\n",
    "        try:\n",
    "            # XPATH로 차례로 접근\n",
    "            link = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable(\n",
    "                    (By.XPATH, f'//*[@id=\"section_price\"]/div[4]/ul/li[{i}]/div/div[1]')))\n",
    "\n",
    "            link.click()\n",
    "\n",
    "            text = link.text\n",
    "            time.sleep(2)\n",
    "\n",
    "            # 새 탭으로 전환\n",
    "            if len(driver.window_handles) > 1:\n",
    "                new_window = [window for window in driver.window_handles if window != original_window][0]\n",
    "                driver.switch_to.window(new_window)\n",
    "                time.sleep(1)\n",
    "\n",
    "                # 새 탭의 URL 가져오기\n",
    "                current_url = driver.current_url\n",
    "\n",
    "                # 도메인 추출\n",
    "                parsed_url = urlparse(current_url)\n",
    "                domain = parsed_url.netloc\n",
    "                base_url = f\"{parsed_url.scheme}://{parsed_url.netloc}\"\n",
    "\n",
    "                # 스마트스토어 리스트 추출\n",
    "                if base_url == 'https://smartstore.naver.com':\n",
    "                    path_seg = parsed_url.path.split('/')\n",
    "                    smart_id = path_seg[1]\n",
    "                    qna = base_url + '/' + path_seg[1] + '/qna'\n",
    "\n",
    "                    # storelink 안에 리스트가 없는 경우만 추가 (중복 방지)\n",
    "                    if qna not in storelink:\n",
    "                        storelink.append(qna)\n",
    "                        storename.append(text)\n",
    "                        print(f\"도메인 주소: {domain}\") # ex) smartstore.naver.com\n",
    "                        print(f\"base_url: {base_url}\") # ex) https://smartstore.naver.com\n",
    "                        print(f\"smart_id: {smart_id}\") # ex) isround\n",
    "                        print(f\"text: {text}\")\n",
    "                        print()\n",
    "                    \n",
    "                    else:\n",
    "                        print('새 창이 안열림.')\n",
    "                        print()\n",
    "\n",
    "                # 새 탭 닫기 및 원래 탭으로 복귀\n",
    "                driver.close()\n",
    "                driver.switch_to.window(original_window)\n",
    "                time.sleep(1)\n",
    "\n",
    "        # 오류 발생 시 예외 처리 후 넘어감.\n",
    "        except Exception as e:\n",
    "            print(f'예외 오류 발생 코드: {e}')\n",
    "            continue\n",
    "\n",
    "    driver.quit()\n",
    "    # smartDF = makeLinkDF(storelink, storename)\n",
    "    smartDF = pd.DataFrame({'링크': storelink, '상점': storename})\n",
    "\n",
    "    # 파일 내보내기\n",
    "    smartDF.to_excel(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 스마트스토어 qna 불러와서 텍스트 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 변수 지정\n",
    "file = './rawfile.xlsx'\n",
    "\n",
    "# 파일 불러오기\n",
    "fileDF = pd.read_excel(file)\n",
    "\n",
    "for link in fileDF['링크'][:2]:\n",
    "\n",
    "    # 사이트 진입\n",
    "    agent_option = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(options=agent_option)\n",
    "\n",
    "    user_agent_string = 'Mozilla/5.0'\n",
    "    agent_option.add_argument('user-agent=' + user_agent_string)\n",
    "\n",
    "    # 링크 가져오기\n",
    "    driver.get(link)\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "    # page 개수 가져오기\n",
    "    pagenum = driver.find_elements(By.CLASS_NAME, \"UWN4IvaQza._nlog_click\")\n",
    "\n",
    "    # 해당 페이지 텍스트 담을 리스트 만들기\n",
    "    text_list=[]\n",
    "    for page in pagenum:\n",
    "        page.click()\n",
    "        # 해당 페이지 html 가져오기\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # 텍스트 가져오기\n",
    "        texts = soup.find_all('div', class_='_38rS4qj1Bp')\n",
    "        \n",
    "        for tag in texts:\n",
    "            name_tag = tag.text.strip()\n",
    "            text_list.append(name_tag)\n",
    "    print(text_list)\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로\n",
    "file = './rawfile.xlsx'\n",
    "\n",
    "# 엑셀 파일 불러오기\n",
    "fileDF = pd.read_excel(file)\n",
    "\n",
    "for link in fileDF['링크'][:3]:\n",
    "    # 웹 드라이버 초기화\n",
    "    agent_option = webdriver.ChromeOptions()\n",
    "    user_agent_string = 'Mozilla/5.0'\n",
    "    agent_option.add_argument('user-agent=' + user_agent_string)\n",
    "    driver = webdriver.Chrome(options=agent_option)\n",
    "\n",
    "    try:\n",
    "        # 웹사이트 접속\n",
    "        driver.get(link)\n",
    "        driver.implicitly_wait(5)\n",
    "\n",
    "        # 텍스트를 저장할 리스트 초기화\n",
    "        text_list = []\n",
    "\n",
    "        # 페이지 버튼 요소 가져오기\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located(\n",
    "                (By.CLASS_NAME, \"UWN4IvaQza._nlog_click\")))\n",
    "        pagenum = driver.find_elements(By.CLASS_NAME, \"UWN4IvaQza._nlog_click\")\n",
    "\n",
    "        for i in range(len(pagenum)):\n",
    "            # 페이지 요소를 매 루프마다 재조회하여 최신화\n",
    "            driver.implicitly_wait(2)\n",
    "            pagenum = driver.find_elements(By.CLASS_NAME, \"UWN4IvaQza._nlog_click\")\n",
    "            page = pagenum[i]\n",
    "\n",
    "            # (필요시) 요소로 스크롤 이동\n",
    "            ActionChains(driver).move_to_element(page).perform()\n",
    "\n",
    "            # 페이지 버튼 클릭\n",
    "            driver.implicitly_wait(2)\n",
    "            page.click()\n",
    "\n",
    "            # 페이지 HTML 가져오기\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            # 텍스트 데이터 추출\n",
    "            texts = soup.find_all('div', class_='_38rS4qj1Bp')\n",
    "            for tag in texts:\n",
    "                name_tag = tag.text.strip()\n",
    "                text_list.append(name_tag)\n",
    "\n",
    "        # 결과 출력\n",
    "        print(text_list)\n",
    "\n",
    "    finally:\n",
    "        # 드라이버 종료\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './sample.xlsx'\n",
    "textfile = './textfile.xlsx'\n",
    "\n",
    "# 엑셀 파일 읽기\n",
    "fileDF = pd.read_excel(file)\n",
    "\n",
    "# 텍스트 저장할 리스트\n",
    "text_list = []\n",
    "\n",
    "for link in fileDF['링크']:\n",
    "    # WebDriver 초기화\n",
    "    agent_option = webdriver.ChromeOptions()\n",
    "    user_agent_string = 'Mozilla/5.0'\n",
    "    agent_option.add_argument('user-agent=' + user_agent_string)\n",
    "    driver = webdriver.Chrome(options=agent_option)\n",
    "\n",
    "    try:\n",
    "        # 링크 열기\n",
    "        driver.get(link)\n",
    "        driver.implicitly_wait(5)\n",
    "\n",
    "        # 텍스트 추출 리스트 초기화\n",
    "        text_in_page = []\n",
    "\n",
    "        # 페이지 버튼 가져오기\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"UWN4IvaQza._nlog_click\"))\n",
    "        )\n",
    "        page_num = driver.find_elements(By.CLASS_NAME, \"UWN4IvaQza._nlog_click\")\n",
    "        button = len(page_num)\n",
    "\n",
    "        # 각 페이지 버튼 클릭\n",
    "        for i in range(button):\n",
    "            try:\n",
    "                # 페이지 버튼 최신화\n",
    "                page_num = driver.find_elements(By.CLASS_NAME, \"UWN4IvaQza._nlog_click\")\n",
    "                page = page_num[i]\n",
    "\n",
    "                # 클릭\n",
    "                page.click()\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_all_elements_located((By.CLASS_NAME, \"_38rS4qj1Bp\"))\n",
    "                )\n",
    "\n",
    "                # HTML 가져오기\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                # 필요한 데이터 추출\n",
    "                texts = [tag.text.strip() for tag in soup.find_all('div', class_='_38rS4qj1Bp')]\n",
    "                text_in_page.extend(texts)\n",
    "\n",
    "            except StaleElementReferenceException:\n",
    "                print(\"StaleElementReferenceException\")\n",
    "                continue\n",
    "\n",
    "        # 한 링크에 대한 모든 데이터 추가\n",
    "        text_list.append(text_in_page)\n",
    "\n",
    "    finally:\n",
    "        # WebDriver 종료\n",
    "        driver.quit()\n",
    "\n",
    "# 결과 저장\n",
    "textDF = pd.DataFrame({'텍스트': text_list})\n",
    "textDF.to_excel(textfile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
